#!/usr/bin/env python3
"""
æµ‹è¯•çœŸå®çš„ CRA T4012 PDF æ–‡æ¡£
"""

import fitz
import time
import json
from pathlib import Path

def test_real_t4012():
    """æµ‹è¯•çœŸå®çš„ T4012 PDF"""
    pdf_path = Path("pdf/t4012-24e.pdf")

    if not pdf_path.exists():
        print(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {pdf_path}")
        return False

    print(f"ğŸš€ æµ‹è¯•çœŸå® CRA T4012 PDF: {pdf_path}")
    print("=" * 50)

    try:
        # è·å–æ–‡ä»¶å¤§å°
        file_size = pdf_path.stat().st_size / (1024 * 1024)  # MB
        print(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size:.1f} MB")

        # æ‰“å¼€ PDF
        start_time = time.time()
        doc = fitz.open(str(pdf_path))
        open_time = time.time() - start_time

        total_pages = len(doc)
        print(f"ğŸ“„ æ€»é¡µæ•°: {total_pages}")
        print(f"â±ï¸  æ‰“å¼€æ—¶é—´: {open_time:.2f} ç§’")

        # è·å–å…ƒæ•°æ®
        metadata = doc.metadata
        print(f"\nğŸ“‹ æ–‡æ¡£å…ƒæ•°æ®:")
        print(f"  æ ‡é¢˜: {metadata.get('title', 'N/A')}")
        print(f"  ä½œè€…: {metadata.get('author', 'N/A')}")
        print(f"  åˆ›å»ºè€…: {metadata.get('creator', 'N/A')}")
        print(f"  ç”Ÿäº§è€…: {metadata.get('producer', 'N/A')}")

        # æµ‹è¯•å¤„ç†å‰5é¡µ
        test_pages = min(5, total_pages)
        print(f"\nğŸ” æµ‹è¯•å¤„ç†å‰ {test_pages} é¡µ...")

        total_text = ""
        pages_with_text = 0
        pages_needing_ocr = 0
        total_chars = 0

        page_results = []

        for page_num in range(test_pages):
            print(f"ğŸ“– å¤„ç†ç¬¬ {page_num + 1}/{test_pages} é¡µ...")
            page_start = time.time()

            page = doc[page_num]
            text = page.get_text()

            page_time = time.time() - page_start

            # è¯„ä¼°æ–‡æœ¬è´¨é‡
            text_quality = 0.0
            if text.strip():
                words = text.split()
                complete_words = sum(1 for word in words if word.isalpha() or '.' in word or ',' in word)
                text_quality = complete_words / len(words) if words else 0
                pages_with_text += 1

                # æ£€æŸ¥æ˜¯å¦éœ€è¦ OCR (è´¨é‡ä½)
                if text_quality < 0.3:
                    pages_needing_ocr += 1

                total_chars += len(text)
                total_text += f"\n=== Page {page_num + 1} ===\n{text}\n"

            # æ£€æŸ¥é¡µé¢æ˜¯å¦æœ‰å›¾åƒ
            images = page.get_images()
            has_images = len(images) > 0

            page_result = {
                'page': page_num + 1,
                'chars': len(text),
                'words': len(text.split()),
                'quality': text_quality,
                'has_images': has_images,
                'image_count': len(images),
                'processing_time': page_time
            }
            page_results.append(page_result)

            print(f"  âœ… æ–‡æœ¬: {len(text)} å­—ç¬¦, {len(text.split())} è¯")
            print(f"  ğŸ“Š è´¨é‡: {text_quality:.2f}, å›¾åƒ: {len(images)} ä¸ª")
            print(f"  â±ï¸  å¤„ç†æ—¶é—´: {page_time:.3f} ç§’")

        # è®¡ç®—ç»Ÿè®¡
        total_processing_time = time.time() - start_time
        avg_quality = sum(r['quality'] for r in page_results) / len(page_results)

        print(f"\nğŸ“Š å¤„ç†ç»Ÿè®¡ (å‰{test_pages}é¡µ):")
        print(f"  â±ï¸  æ€»å¤„ç†æ—¶é—´: {total_processing_time:.2f} ç§’")
        print(f"  ğŸ“„ æˆåŠŸå¤„ç†é¡µæ•°: {pages_with_text}/{test_pages}")
        print(f"  ğŸ” å¯èƒ½éœ€è¦OCR: {pages_needing_ocr} é¡µ")
        print(f"  ğŸ“ æ€»å­—ç¬¦æ•°: {total_chars:,}")
        print(f"  ğŸ“ˆ å¹³å‡æ–‡æœ¬è´¨é‡: {avg_quality:.2f}")

        if total_processing_time > 0:
            pages_per_sec = test_pages / total_processing_time
            print(f"  âš¡ å¤„ç†é€Ÿåº¦: {pages_per_sec:.2f} é¡µ/ç§’")

        # æŸ¥æ‰¾å…³é”®è¯
        print(f"\nğŸ¯ å…³é”®è¯æœç´¢ (å‰{test_pages}é¡µ):")
        keywords = [
            "capital gains", "business income", "tax credits",
            "RRSP", "deductions", "filing", "CRA", "T4012"
        ]

        found_keywords = {}
        for keyword in keywords:
            count = total_text.lower().count(keyword.lower())
            if count > 0:
                found_keywords[keyword] = count
                print(f"  âœ… {keyword}: {count} æ¬¡")

        # æ£€æŸ¥ç« èŠ‚ç»“æ„
        print(f"\nğŸ“– ç« èŠ‚æ£€æµ‹ (å‰{test_pages}é¡µ):")
        lines = total_text.split('\n')
        potential_chapters = []

        for line in lines[:100]:  # åªæ£€æŸ¥å‰100è¡Œ
            line = line.strip()
            if len(line) > 10 and len(line) < 100:
                # å¯èƒ½çš„ç« èŠ‚æ ‡é¢˜
                if any(word in line.lower() for word in ['chapter', 'section', 'part']):
                    potential_chapters.append(line)
                elif line.isupper() and len(line.split()) <= 10:
                    potential_chapters.append(line)

        if potential_chapters:
            print("  å‘ç°å¯èƒ½çš„ç« èŠ‚:")
            for chapter in potential_chapters[:5]:
                print(f"    - {chapter}")
        else:
            print("  æœªå‘ç°æ˜æ˜¾çš„ç« èŠ‚ç»“æ„")

        # æ˜¾ç¤ºæ–‡æœ¬æ ·æœ¬
        print(f"\nğŸ“ æ–‡æœ¬æ ·æœ¬ (ç¬¬1é¡µå‰200å­—ç¬¦):")
        print("-" * 50)
        first_page_text = page_results[0]['chars'] > 0
        if first_page_text:
            # è·å–ç¬¬ä¸€é¡µçš„æ–‡æœ¬
            doc_test = fitz.open(str(pdf_path))
            page = doc_test[0]
            sample_text = page.get_text()[:200]
            doc_test.close()
            print(sample_text)
        else:
            print("ç¬¬ä¸€é¡µæ²¡æœ‰æå–åˆ°æ–‡æœ¬")
        print("-" * 50)

        # ä¿å­˜ç»“æœ
        result = {
            'pdf_file': str(pdf_path),
            'file_size_mb': file_size,
            'total_pages': total_pages,
            'tested_pages': test_pages,
            'processing_time': total_processing_time,
            'pages_with_text': pages_with_text,
            'pages_needing_ocr': pages_needing_ocr,
            'total_chars': total_chars,
            'average_quality': avg_quality,
            'keywords': found_keywords,
            'metadata': {
                'title': metadata.get('title'),
                'author': metadata.get('author'),
                'creator': metadata.get('creator')
            },
            'page_results': page_results
        }

        result_file = "t4012_test_result.json"
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜: {result_file}")

        doc.close()

        # è¯„ä¼°ç»“æœ
        print(f"\nğŸ¯ å¤„ç†è¯„ä¼°:")
        if avg_quality > 0.7:
            print("  âœ… æ–‡æœ¬è´¨é‡ä¼˜ç§€ - é€‚åˆç›´æ¥å¤„ç†")
        elif avg_quality > 0.4:
            print("  âœ… æ–‡æœ¬è´¨é‡è‰¯å¥½ - å¯ä»¥ç›´æ¥å¤„ç†")
        elif avg_quality > 0.2:
            print("  âš ï¸ æ–‡æœ¬è´¨é‡ä¸€èˆ¬ - å»ºè®®ä½¿ç”¨OCRè¡¥å……")
        else:
            print("  âŒ æ–‡æœ¬è´¨é‡è¾ƒå·® - éœ€è¦OCRå¤„ç†")

        if pages_per_sec > 1:
            print("  âœ… å¤„ç†é€Ÿåº¦ä¼˜ç§€")
        elif pages_per_sec > 0.5:
            print("  âœ… å¤„ç†é€Ÿåº¦è‰¯å¥½")
        else:
            print("  âš ï¸ å¤„ç†é€Ÿåº¦è¾ƒæ…¢")

        print(f"\nğŸ‰ T4012 PDF æµ‹è¯•å®Œæˆ!")
        print(f"âœ… PyMuPDF å¯ä»¥æˆåŠŸå¤„ç† {total_pages} é¡µçš„å¤§å‹ CRA æ–‡æ¡£")
        print(f"âœ… æ–‡æœ¬æå–è´¨é‡: {avg_quality:.2f}")
        print(f"âœ… å¤„ç†é€Ÿåº¦: {pages_per_sec:.2f} é¡µ/ç§’")

        return True

    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")
        import traceback
        print(f"è¯¦ç»†é”™è¯¯: {traceback.format_exc()}")
        return False

def estimate_full_processing():
    """ä¼°ç®—å®Œæ•´å¤„ç†æ—¶é—´"""
    print(f"\nâ±ï¸ å®Œæ•´æ–‡æ¡£å¤„ç†ä¼°ç®—:")

    result_file = Path("t4012_test_result.json")
    if result_file.exists():
        with open(result_file, 'r', encoding='utf-8') as f:
            result = json.load(f)

        tested_pages = result['tested_pages']
        processing_time = result['processing_time']
        total_pages = result['total_pages']

        estimated_time = (processing_time / tested_pages) * total_pages

        print(f"  åŸºäºå‰ {tested_pages} é¡µçš„ç»“æœ:")
        print(f"  ğŸ“„ æ€»é¡µæ•°: {total_pages}")
        print(f"  â±ï¸ é¢„ä¼°å®Œæ•´å¤„ç†æ—¶é—´: {estimated_time:.1f} ç§’ ({estimated_time/60:.1f} åˆ†é’Ÿ)")

        if estimated_time < 60:
            print("  âœ… å¤„ç†æ—¶é—´åˆç† (< 1åˆ†é’Ÿ)")
        elif estimated_time < 300:
            print("  âœ… å¤„ç†æ—¶é—´å¯æ¥å— (< 5åˆ†é’Ÿ)")
        else:
            print("  âš ï¸ å¤„ç†æ—¶é—´è¾ƒé•¿ (> 5åˆ†é’Ÿ)")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ§ª CRA T4012 çœŸå®æ–‡æ¡£æµ‹è¯•")
    print("=" * 40)

    if test_real_t4012():
        estimate_full_processing()
        print(f"\nâœ… æµ‹è¯•æˆåŠŸ! PyMuPDF å®Œå…¨å¯ä»¥å¤„ç†å¤§å‹ CRA PDF æ–‡æ¡£")
    else:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥")

if __name__ == "__main__":
    main()