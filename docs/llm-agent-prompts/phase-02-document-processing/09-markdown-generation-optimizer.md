# ä»»åŠ¡09ï¼šMarkdown ç”Ÿæˆä¼˜åŒ–ï¼ˆCRA æ–‡æ¡£ä¸“ç”¨ï¼‰

## ä»»åŠ¡ç›®æ ‡

ä¼˜åŒ–ä» Skill Seeker PyMuPDF æå–çš„ CRA æ–‡æ¡£å†…å®¹ï¼Œè¿›è¡Œæ¸…æ´—ã€æ ¼å¼åŒ–ã€å¢å¼ºå’Œè´¨é‡æ£€æŸ¥ï¼Œç¡®ä¿ç”Ÿæˆçš„ç¨åŠ¡çŸ¥è¯†åº“ Skill æ–‡ä»¶ç»“æ„æ¸…æ™°ã€æ ¼å¼ç»Ÿä¸€ã€ç¬¦åˆ MVP ç³»ç»Ÿè§„èŒƒã€‚

**æŠ€æœ¯å‡çº§**: é›†æˆ Skill_Seekers çš„å…ˆè¿›æ¨¡æ¿ä¼˜åŒ–æŠ€æœ¯å’Œ AI å†…å®¹å¢å¼ºåŠŸèƒ½ï¼Œå°†åŸºç¡€çš„ Markdown å†…å®¹è½¬æ¢ä¸ºä¸“ä¸šã€å®ç”¨çš„ç¨åŠ¡çŸ¥è¯†æŒ‡å—ï¼Œå®ç°ä»æ–‡æ¡£åˆ°çŸ¥è¯†çš„æ™ºèƒ½åŒ–è½¬æ¢ã€‚

## æŠ€æœ¯è¦æ±‚

**å¤„ç†å†…å®¹ï¼š**
- ä¼˜åŒ– PyMuPDF æå–çš„æ–‡æœ¬å†…å®¹
- ç»Ÿä¸€ç¨åŠ¡æ–‡æ¡£æ ¼å¼è§„èŒƒ
- ä¿®å¤è¡¨æ ¼ç»“æ„å¯¹é½é—®é¢˜
- å¢å¼ºæ³•è§„æ¡æ¬¾å¯è¯»æ€§
- ç”Ÿæˆç¬¦åˆ MVP ç³»ç»Ÿçš„å…ƒæ•°æ®

**Skill_Seekers é›†æˆç‰¹æ€§ï¼š**
- **AI æ¨¡æ¿ä¼˜åŒ–**ï¼šåŸºäº Claude Code Max çš„æ™ºèƒ½æ¨¡æ¿è½¬æ¢
- **å†…å®¹è´¨é‡æå‡**ï¼šä»åŸºç¡€æ–‡æ¡£åˆ°å®ç”¨æŒ‡å—çš„ AI å¢å¼º
- **æ™ºèƒ½ç»“æ„ä¼˜åŒ–**ï¼šè‡ªåŠ¨åŒ–çš„å†…å®¹ç»„ç»‡å’Œå¯¼èˆªç”Ÿæˆ
- **ç¨åŠ¡ä¸“ä¸šåŒ–**ï¼šé’ˆå¯¹ CRA æ–‡æ¡£çš„ä¸“ä¸šæ ¼å¼å¤„ç†

**è¾“å‡ºè§„èŒƒï¼š**
- ç¬¦åˆ CommonMark æ ‡å‡†
- å…¼å®¹ MVP Skill ç³»ç»Ÿ YAML Front Matter
- ä¼˜åŒ– CRA æ–‡æ¡£å¯¼èˆªç»“æ„
- æå–ç¨åŠ¡ä¸“ä¸šæœ¯è¯­å’Œå…³é”®è¯
- AI å¢å¼ºçš„å®ç”¨å†…å®¹ç»“æ„

## å®ç°æ­¥éª¤

### 1. åˆ›å»º CRA æ–‡æ¡£ä¼˜åŒ–å™¨æ¨¡å—

```bash
touch backend/src/document_processor/markdown_optimizer.py
touch backend/src/document_processor/ai_template_optimizer.py
touch backend/src/document_processor/template_engine.py
```

### 2. å®ç° CRA æ–‡æ¡£ä¸“ç”¨æ¸…ç†åŠŸèƒ½

ä¼˜åŒ– PDF æå–å†…å®¹ï¼š
- æ¸…ç† PyMuPDF æå–çš„é¡µçœ‰é¡µè„š
- å»é™¤é‡å¤çš„ CRA æ°´å°ä¿¡æ¯
- ç»Ÿä¸€æ¢è¡Œç¬¦å’Œæ®µè½ç»“æ„
- å¤„ç†åŒè¯­å†…å®¹ï¼ˆè‹±/æ³•ï¼‰

### 3. å®ç°ç¨åŠ¡æ–‡æ¡£æ ¼å¼åŒ–åŠŸèƒ½

æ ‡å‡†åŒ–ç¨åŠ¡æ–‡æ¡£æ ¼å¼ï¼š
- ç»Ÿä¸€æ³•è§„æ¡æ¬¾æ ¼å¼
- è§„èŒƒç¨åŠ¡æœ¯è¯­è¡¨è¿°
- ä¿®å¤ CRA è¡¨æ ¼ç»“æ„
- ä¼˜åŒ–ç¨æ”¶è®¡ç®—è¯´æ˜

### 4. å®ç° MVP Skill å…ƒæ•°æ®ç”Ÿæˆ

ç”Ÿæˆç¬¦åˆ MVP ç³»ç»Ÿçš„å…ƒæ•°æ®ï¼š
- å…¼å®¹ skill_loader.py çš„ YAML æ ¼å¼
- ç”Ÿæˆç¨åŠ¡ä¸“ç”¨æ ‡ç­¾å’Œåˆ†ç±»
- æå–å…³é”®ç¨åŠ¡æ¦‚å¿µ
- è®°å½• CRA æ–‡æ¡£æ¥æºå’Œç‰ˆæœ¬

### 5. å®ç° CRA æ–‡æ¡£è´¨é‡æ£€æŸ¥

éªŒè¯ç¨åŠ¡æ–‡æ¡£è´¨é‡ï¼š
- æ£€æŸ¥æ³•è§„æ¡æ¬¾å®Œæ•´æ€§
- éªŒè¯ç¨åŠ¡è®¡ç®—å…¬å¼
- æ£€æµ‹æœ¯è¯­ä¸€è‡´æ€§
- è¯„ä¼°ç”¨æˆ·å¯è¯»æ€§

## å…³é”®ä»£ç æç¤º

**CRA æ–‡æ¡£ Markdown ä¼˜åŒ–å™¨å®ç°ï¼š**

```python
import re
from typing import Dict, List, Optional
from pathlib import Path
import yaml
from datetime import datetime

class CRADocumentOptimizer:
    """CRA æ–‡æ¡£ Markdown ä¼˜åŒ–å™¨ï¼ˆé›†æˆ Skill_Seekers AI å¢å¼ºæŠ€æœ¯ï¼‰"""

    def __init__(self):
        self.stats = {
            "cleaned": 0,
            "formatted": 0,
            "metadata_added": 0,
            "cra_processed": 0,
            "ai_enhanced": 0,
            "template_optimized": 0
        }

        # Skill_Seekers AI å¢å¼ºé…ç½®
        self.ai_config = {
            "enable_ai_enhancement": True,
            "enable_template_optimization": True,
            "use_claude_max": True,
            "max_enhancement_attempts": 3
        }

        # åˆå§‹åŒ– AI å¢å¼ºç»„ä»¶
        if self.ai_config["enable_ai_enhancement"]:
            self.ai_enhancer = AITemplateEnhancer()
            self.template_engine = IntelligentTemplateEngine()

        # CRA æ–‡æ¡£ä¸“ç”¨æ¨¡å¼ï¼ˆå¢å¼ºç‰ˆï¼‰
        self.cra_patterns = {
            "header_footer": [
                r"^Canada Revenue Agency\s+Agence du revenu du Canada\s*$",
                r"^Page\s+\d+\s*$",
                r"^T4012\s*.*?$",
                r"^www\.canada\.ca/revenue-agency\s*$",
                r"^T4012.*E.*\d{4}$",  # T4012 æ ‡é¢˜æ¨¡å¼
                r"^.*income\s+tax.*guide.*$"  # æ‰€å¾—ç¨æŒ‡å—æ¨¡å¼
            ],
            "tax_terms": [
                r"capital\s+gains?",
                r"business\s+income",
                r"tax\s+credits?",
                r"deductions?",
                r"RRSP",
                r"GST/HST",
                r"taxable\s+income",
                r"non.*taxable\s+income",
                r"employment\s+income",
                r"investment\s+income"
            ],
            "legal_phrases": [
                r"must\s+.*",
                r"shall\s+.*",
                r"required\s+to\s+.*",
                r"according\s+to\s+.*",
                r"as\s+per\s+.*",
                r"subject\s+to\s+.*",
                r"liable\s+for\s+.*"
            ],
            "calculation_indicators": [
                r"calculate\s+.*",
                r"formula\s+.*",
                r"=\s*\d+.*%",
                r"\$\s*\d+",
                r"rate\s+of\s+.*%",
                r"\d+%\s+of"
            ]
        }

        # Skill_Seekers æ¨¡æ¿ä¼˜åŒ–è§„åˆ™
        self.template_rules = {
            "section_hierarchy": [
                (r"^# (.+)$", 1, "main_title"),
                (r"^## (.+)$", 2, "major_section"),
                (r"^### (.+)$", 3, "subsection"),
                (r"^#### (.+)$", 4, "detail_section")
            ],
            "list_patterns": [
                r"^[-*+]\s+",  # æ— åºåˆ—è¡¨
                r"^\d+\.\s+",  # æœ‰åºåˆ—è¡¨
                r"^[a-z]\.\s+"   # å­—æ¯åˆ—è¡¨
            ],
            "emphasis_patterns": [
                r"\*\*(.+?)\*\*",  # ç²—ä½“
                r"_(.+?)_",        # æ–œä½“
                r"`(.+?)`"        # ä»£ç 
            ]
        }

    def optimize_cra_content(
        self,
        raw_markdown: str,
        source_file: Optional[str] = None,
        document_type: str = "cra_tax_guide",
        enable_ai_enhancement: Optional[bool] = None
    ) -> str:
        """
        å…¨æµç¨‹ä¼˜åŒ– CRA æ–‡æ¡£å†…å®¹ï¼ˆé›†æˆ Skill_Seekers AI å¢å¼ºï¼‰

        Args:
            raw_markdown: ä» PyMuPDF æå–çš„åŸå§‹å†…å®¹
            source_file: æº PDF æ–‡ä»¶å
            document_type: CRA æ–‡æ¡£ç±»å‹
            enable_ai_enhancement: æ˜¯å¦å¯ç”¨ AI å¢å¼ºï¼ˆè¦†ç›–é…ç½®ï¼‰

        Returns:
            ä¼˜åŒ–åçš„ Markdown
        """
        # ç¡®å®šæ˜¯å¦å¯ç”¨ AI å¢å¼º
        ai_enabled = enable_ai_enhancement if enable_ai_enhancement is not None else self.ai_config["enable_ai_enhancement"]

        # 1. CRA ä¸“ç”¨æ¸…ç†
        cleaned = self._clean_cra_content(raw_markdown)

        # 2. ç¨åŠ¡æ–‡æ¡£æ ¼å¼åŒ–
        formatted = self._format_tax_markdown(cleaned)

        # 3. Skill_Seekers AI å¢å¼ºå’Œæ¨¡æ¿ä¼˜åŒ–
        if ai_enabled:
            enhanced = self._apply_ai_enhancement(formatted, source_file, document_type)
            formatted = enhanced

        # 4. ç”Ÿæˆ MVP å…¼å®¹å…ƒæ•°æ®
        metadata = self._generate_mvp_metadata(formatted, source_file, document_type)

        # 5. ç»„åˆæœ€ç»ˆè¾“å‡º
        final_markdown = self._combine_with_metadata(metadata, formatted)

        self.stats["cra_processed"] += 1
        return final_markdown

    def _apply_ai_enhancement(self, content: str, source_file: Optional[str], document_type: str) -> str:
        """åº”ç”¨ Skill_Seekers AI å¢å¼ºæŠ€æœ¯"""

        try:
            # 1. æ™ºèƒ½æ¨¡æ¿ä¼˜åŒ–
            if self.ai_config["enable_template_optimization"]:
                optimized = self.template_engine.optimize_template(content, document_type)
                self.stats["template_optimized"] += 1
                content = optimized

            # 2. AI å†…å®¹å¢å¼º
            enhanced_content = self.ai_enhancer.enhance_content(
                content=content,
                source_file=source_file,
                document_type=document_type,
                enhancement_level="comprehensive"
            )

            self.stats["ai_enhanced"] += 1
            return enhanced_content

        except Exception as e:
            print(f"âš ï¸ AI å¢å¼ºå¤±è´¥ï¼Œä½¿ç”¨åŸºç¡€æ ¼å¼åŒ–: {e}")
            return content

    def _clean_cra_content(self, markdown: str) -> str:
        """æ¸…ç† CRA æ–‡æ¡£å†…å®¹"""
        # åˆ é™¤é¡µçœ‰é¡µè„š
        for pattern in self.cra_patterns["header_footer"]:
            markdown = re.sub(pattern, "", markdown, flags=re.MULTILINE | re.IGNORECASE)

        # åˆ é™¤é¡µç 
        markdown = re.sub(r"^\s*\d+\s*$", "", markdown, flags=re.MULTILINE)

        # æ¸…ç†å¤šä½™ç©ºè¡Œå’Œç©ºç™½å­—ç¬¦
        markdown = re.sub(r"\n{3,}", "\n\n", markdown)
        lines = [line.rstrip() for line in markdown.split("\n") if line.strip()]
        markdown = "\n".join(lines)

        self.stats["cleaned"] += 1
        return markdown

  
    def _format_tax_markdown(self, markdown: str) -> str:
        """æ ¼å¼åŒ–ç¨åŠ¡æ–‡æ¡£ Markdown"""
        # è§„èŒƒåŒ–æ ‡é¢˜ï¼ˆç¡®ä¿ # åæœ‰ç©ºæ ¼ï¼‰
        markdown = re.sub(r"^(#{1,6})([^ #])", r"\1 \2", markdown, flags=re.MULTILINE)

        # è§„èŒƒåŒ–åˆ—è¡¨ï¼ˆç¡®ä¿ - æˆ– * åæœ‰ç©ºæ ¼ï¼‰
        markdown = re.sub(r"^([*\-])([^ ])", r"\1 \2", markdown, flags=re.MULTILINE)

        # ä¿®å¤ CRA è¡¨æ ¼ç»“æ„
        markdown = self._fix_cra_tables(markdown)

        # æ ¼å¼åŒ–æ³•è§„æ¡æ¬¾
        markdown = self._format_legal_sections(markdown)

        # ä¼˜åŒ–ç¨åŠ¡è®¡ç®—è¯´æ˜
        markdown = self._enhance_tax_calculations(markdown)

        self.stats["formatted"] += 1
        return markdown

    def _fix_cra_tables(self, markdown: str) -> str:
        """ä¿®å¤ CRA æ–‡æ¡£è¡¨æ ¼"""
        lines = markdown.split("\n")
        fixed_lines = []

        for i, line in enumerate(lines):
            # æ£€æµ‹è¡¨æ ¼è¡Œ
            if "|" in line and not line.strip().startswith("|"):
                # ç¡®ä¿è¡¨æ ¼è¡Œä»¥ | å¼€å§‹å’Œç»“æŸ
                if not line.startswith("|"):
                    line = "| " + line
                if not line.endswith("|"):
                    line = line + " |"
                fixed_lines.append(line)
            elif re.match(r"^\s*\|[\s\-:|]+\|", line):
                # è¡¨æ ¼åˆ†éš”è¡Œ
                parts = [p.strip() for p in line.split("|")]
                parts = [p if p else "---" for p in parts]
                fixed_line = "| " + " | ".join(parts[1:-1]) + " |"
                fixed_lines.append(fixed_line)
            else:
                fixed_lines.append(line)

        return "\n".join(fixed_lines)

    def _format_legal_sections(self, markdown: str) -> str:
        """æ ¼å¼åŒ–æ³•è§„æ¡æ¬¾"""
        lines = markdown.split("\n")
        formatted_lines = []

        for line in lines:
            # è¯†åˆ«æ³•è§„æ¡æ¬¾å¹¶å¼ºåŒ–æ ¼å¼
            for pattern in self.cra_patterns["legal_phrases"]:
                if re.search(pattern, line, re.IGNORECASE):
                    # æ·»åŠ æ³•è§„æ ‡è®°
                    line = f"âš–ï¸ **{line.strip()}**"
                    break

            # è¯†åˆ«ç¨åŠ¡æœ¯è¯­å¹¶é«˜äº®
            for term in self.cra_patterns["tax_terms"]:
                if re.search(rf"\b{term}\b", line, re.IGNORECASE):
                    line = re.sub(
                        rf"\b({term})\b",
                        r"**\1**",
                        line,
                        flags=re.IGNORECASE
                    )
                    break

            formatted_lines.append(line)

        return "\n".join(formatted_lines)

    def _enhance_tax_calculations(self, markdown: str) -> str:
        """å¢å¼ºç¨åŠ¡è®¡ç®—è¯´æ˜"""
        # è¯†åˆ«ç™¾åˆ†æ¯”è®¡ç®—
        markdown = re.sub(
            r"(\d+)%",
            r"**\1%**",
            markdown
        )

        # è¯†åˆ«é‡‘é¢
        markdown = re.sub(
            r"\$(\d{1,3}(,\d{3})*(\.\d{2})?)",
            r"**$\1**",
            markdown
        )

        # è¯†åˆ«è®¡ç®—å…¬å¼
        markdown = re.sub(
            r"([A-Z]\s*=\s*[\d\+\-\*\/\(\)\s\$%,\.]+)",
            r"`\1`",
            markdown
        )

        return markdown

    def _generate_mvp_metadata(
        self,
        markdown: str,
        source_file: Optional[str],
        document_type: str
    ) -> Dict:
        """ç”Ÿæˆ MVP Skill å…¼å®¹çš„å…ƒæ•°æ®"""
        # æå–ç¬¬ä¸€ä¸ªä¸€çº§æ ‡é¢˜ä½œä¸ºæ ‡é¢˜
        title_match = re.search(r"^#\s+(.+)$", markdown, re.MULTILINE)
        title = title_match.group(1) if title_match else "CRA ç¨åŠ¡æ–‡æ¡£"

        # æå–ç¨åŠ¡å…³é”®è¯
        tax_keywords = self._extract_tax_keywords(markdown)

        # ç”Ÿæˆç¨åŠ¡ä¸“ç”¨æ ‡ç­¾
        tags = ["ç¨åŠ¡", "åŠ æ‹¿å¤§", "CRA", "T4012"] + tax_keywords

        # ç”Ÿæˆç¨åŠ¡æ‘˜è¦
        summary = self._generate_tax_summary(markdown)

        # æ£€æµ‹ç›®æ ‡å—ä¼—
        target_audience = self._identify_tax_audience(markdown)

        metadata = {
            "id": self._generate_skill_id(title, source_file),
            "title": title,
            "tags": tags,
            "description": summary,
            "domain": "tax",
            "priority": self._determine_priority(markdown),
            "version": "1.0.0",
            "author": "CRA Document Processor",
            "created_at": datetime.now().isoformat(),
            "source": f"CRA {source_file or 'T4012'}",
            "target_audience": target_audience,
            "tax_categories": tax_keywords
        }

        self.stats["metadata_added"] += 1
        return metadata

    def _extract_tax_keywords(self, markdown: str) -> List[str]:
        """æå–ç¨åŠ¡å…³é”®è¯"""
        keywords = []

        # ä½¿ç”¨é¢„å®šä¹‰çš„ç¨åŠ¡æœ¯è¯­
        for term in self.cra_patterns["tax_terms"]:
            if re.search(rf"\b{term}\b", markdown, re.IGNORECASE):
                keywords.append(term.replace(" ", "-").lower())

        # æå–æ ‡é¢˜ä¸­çš„å…³é”®è¯
        headings = re.findall(r"^#{2,6}\s+(.+)$", markdown, re.MULTILINE)
        for heading in headings:
            # æ¸…ç†æ ‡é¢˜
            clean_heading = re.sub(r"[^\w\s]", "", heading)
            words = clean_heading.split()
            keywords.extend([w.lower() for w in words if len(w) > 3])

        return list(set(keywords))[:10]  # æœ€å¤š10ä¸ªå…³é”®è¯

    def _generate_tax_summary(self, markdown: str, max_length: int = 150) -> str:
        """ç”Ÿæˆç¨åŠ¡æ–‡æ¡£æ‘˜è¦"""
        # ç§»é™¤æ ‡é¢˜å’Œç‰¹æ®Šæ ¼å¼
        text = re.sub(r"^#+\s+.+$", "", markdown, flags=re.MULTILINE)
        text = re.sub(r"âš–ï¸\s*\*\*([^*]+)\*\*", r"\1", text)
        text = re.sub(r"\*\*([^*]+)\*\*", r"\1", text)

        # è·å–å‰Nä¸ªå­—ç¬¦
        text = text.strip()
        if len(text) > max_length:
            return text[:max_length] + "..."
        return text

    def _identify_tax_audience(self, markdown: str) -> List[str]:
        """è¯†åˆ«ç›®æ ‡å—ä¼—"""
        audience = []
        text_lower = markdown.lower()

        audience_mapping = {
            "individual": ["you", "your", "personal", "individual", "taxpayer"],
            "business": ["business", "corporation", "company", "self-employed", "professional"],
            "investor": ["investor", "investment", "portfolio", "capital", "gains"],
            "accountant": ["accountant", "advisor", "professional", "preparer"]
        }

        for audience_type, keywords in audience_mapping.items():
            if any(keyword in text_lower for keyword in keywords):
                audience.append(audience_type)

        return audience if audience else ["general"]

    def _determine_priority(self, markdown: str) -> str:
        """ç¡®å®šæ–‡æ¡£ä¼˜å…ˆçº§"""
        text_lower = markdown.lower()

        # æ£€æŸ¥é«˜ä¼˜å…ˆçº§æŒ‡æ ‡
        high_priority_indicators = [
            "must", "required", "mandatory", "deadline", "penalty",
            "filing requirement", "due date"
        ]

        for indicator in high_priority_indicators:
            if indicator in text_lower:
                return "high"

        # æ£€æŸ¥æ˜¯å¦æœ‰è®¡ç®—æˆ–è¡¨æ ¼
        if re.search(r"\$?\d+\.?\d*%?", markdown) or "|" in markdown:
            return "medium"

        return "low"

    def _generate_skill_id(self, title: str, source_file: Optional[str]) -> str:
        """ç”Ÿæˆ Skill ID"""
        # æ¸…ç†æ ‡é¢˜
        clean_title = re.sub(r"[^\w\s-]", "", title)
        clean_title = re.sub(r"\s+", "-", clean_title.lower())

        # æ·»åŠ å‰ç¼€
        if source_file and "t4012" in source_file.lower():
            return f"t4012-{clean_title}"
        else:
            return f"cra-{clean_title}"

    def _fix_tables(self, markdown: str) -> str:
        """ä¿®å¤ Markdown è¡¨æ ¼"""
        lines = markdown.split("\n")
        fixed_lines = []

        for i, line in enumerate(lines):
            # æ£€æµ‹è¡¨æ ¼åˆ†éš”è¡Œï¼ˆ|---|---|ï¼‰
            if re.match(r"^\s*\|[\s\-:|]+\|", line):
                # ç¡®ä¿åˆ†éš”ç¬¦æ ¼å¼æ­£ç¡®
                parts = [p.strip() for p in line.split("|")]
                parts = [p if p else "---" for p in parts]
                fixed_line = "| " + " | ".join(parts[1:-1]) + " |"
                fixed_lines.append(fixed_line)
            else:
                fixed_lines.append(line)

        return "\n".join(fixed_lines)

    def _format_code_blocks(self, markdown: str) -> str:
        """æ ¼å¼åŒ–ä»£ç å—"""
        # ä¸ºæ²¡æœ‰è¯­è¨€æ ‡æ³¨çš„ä»£ç å—æ·»åŠ  "text"
        markdown = re.sub(r"```\n", "```text\n", markdown)

        # ç¡®ä¿ä»£ç å—å‰åæœ‰ç©ºè¡Œ
        markdown = re.sub(r"([^\n])\n```", r"\1\n\n```", markdown)
        markdown = re.sub(r"```\n([^\n])", r"```\n\n\1", markdown)

        return markdown

    def _generate_metadata(
        self,
        markdown: str,
        source_file: Optional[str],
        document_type: Optional[str]
    ) -> Dict:
        """ç”Ÿæˆæ–‡æ¡£å…ƒæ•°æ®"""
        # æå–ç¬¬ä¸€ä¸ªä¸€çº§æ ‡é¢˜ä½œä¸ºæ ‡é¢˜
        title_match = re.search(r"^#\s+(.+)$", markdown, re.MULTILINE)
        title = title_match.group(1) if title_match else "æœªå‘½åæ–‡æ¡£"

        # æå–æ‰€æœ‰æ ‡é¢˜ç”Ÿæˆ TOC
        headings = re.findall(r"^(#{1,6})\s+(.+)$", markdown, re.MULTILINE)

        # ç”Ÿæˆç®€å•æ‘˜è¦ï¼ˆå‰200å­—ï¼‰
        summary = self._generate_summary(markdown)

        # æå–å…³é”®è¯ï¼ˆç®€å•å®ç°ï¼‰
        keywords = self._extract_keywords(markdown)

        metadata = {
            "title": title,
            "source": source_file or "unknown",
            "document_type": document_type or "generic",
            "created_at": datetime.now().isoformat(),
            "summary": summary,
            "keywords": keywords,
            "headings_count": len(headings),
            "word_count": len(markdown.split())
        }

        self.stats["metadata_added"] += 1
        return metadata

    def _generate_summary(self, markdown: str, max_length: int = 200) -> str:
        """ç”Ÿæˆæ–‡æ¡£æ‘˜è¦"""
        # ç§»é™¤æ ‡é¢˜å’Œä»£ç å—
        text = re.sub(r"^#+\s+.+$", "", markdown, flags=re.MULTILINE)
        text = re.sub(r"```.*?```", "", text, flags=re.DOTALL)

        # è·å–å‰Nä¸ªå­—ç¬¦
        text = text.strip()
        if len(text) > max_length:
            return text[:max_length] + "..."
        return text

    def _extract_keywords(self, markdown: str, max_keywords: int = 10) -> List[str]:
        """æå–å…³é”®è¯ï¼ˆç®€å•å®ç°ï¼‰"""
        # æå–æ‰€æœ‰æ ‡é¢˜ä½œä¸ºå…³é”®è¯
        headings = re.findall(r"^#{1,6}\s+(.+)$", markdown, re.MULTILINE)

        # ç®€å•å»é‡å’Œæ¸…ç†
        keywords = []
        for heading in headings:
            # ç§»é™¤æ ‡ç‚¹ç¬¦å·
            clean = re.sub(r"[^\w\s\u4e00-\u9fff]", "", heading)
            words = clean.split()
            keywords.extend(words[:3])  # æ¯ä¸ªæ ‡é¢˜å–å‰3ä¸ªè¯

        # å»é‡å¹¶é™åˆ¶æ•°é‡
        keywords = list(dict.fromkeys(keywords))[:max_keywords]
        return keywords

    def _combine_with_metadata(self, metadata: Dict, markdown: str) -> str:
        """å°†å…ƒæ•°æ®å’Œå†…å®¹ç»„åˆ"""
        # ç”Ÿæˆ YAML Front Matter
        front_matter = "---\n" + yaml.dump(metadata, allow_unicode=True, sort_keys=False) + "---\n\n"

        # å¯é€‰ï¼šç”Ÿæˆç›®å½•
        toc = self._generate_toc(markdown)

        if toc:
            return front_matter + toc + "\n\n" + markdown
        else:
            return front_matter + markdown

    def _generate_toc(self, markdown: str) -> str:
        """ç”Ÿæˆç›®å½•ï¼ˆTOCï¼‰"""
        headings = re.findall(r"^(#{1,6})\s+(.+)$", markdown, re.MULTILINE)

        if len(headings) <= 2:
            # æ ‡é¢˜å¤ªå°‘ï¼Œä¸ç”Ÿæˆç›®å½•
            return ""

        toc_lines = ["## ç›®å½•\n"]

        for level, title in headings:
            # è·³è¿‡ä¸€çº§æ ‡é¢˜ï¼ˆé€šå¸¸æ˜¯æ–‡æ¡£æ ‡é¢˜ï¼‰
            if level == "#":
                continue

            # è®¡ç®—ç¼©è¿›
            indent = "  " * (len(level) - 2)

            # ç”Ÿæˆé“¾æ¥é”šç‚¹
            anchor = re.sub(r"[^\w\s\u4e00-\u9fff-]", "", title).replace(" ", "-").lower()

            toc_lines.append(f"{indent}- [{title}](#{anchor})")

        return "\n".join(toc_lines)

    def validate_quality(self, markdown: str) -> Dict:
        """éªŒè¯ Markdown è´¨é‡"""
        issues = []

        # æ£€æŸ¥ç©ºå†…å®¹
        if len(markdown.strip()) < 50:
            issues.append("å†…å®¹è¿‡çŸ­ï¼ˆ<50å­—ç¬¦ï¼‰")

        # æ£€æŸ¥æ˜¯å¦æœ‰æ ‡é¢˜
        if not re.search(r"^#+\s+", markdown, re.MULTILINE):
            issues.append("ç¼ºå°‘æ ‡é¢˜")

        # æ£€æŸ¥è¡¨æ ¼å®Œæ•´æ€§
        table_rows = re.findall(r"^\|.+\|$", markdown, re.MULTILINE)
        if table_rows:
            # æ£€æŸ¥æ˜¯å¦æœ‰åˆ†éš”è¡Œ
            if not any("---" in row for row in table_rows):
                issues.append("è¡¨æ ¼ç¼ºå°‘åˆ†éš”è¡Œ")

        # æ£€æŸ¥ä»£ç å—é—­åˆ
        code_blocks = re.findall(r"```", markdown)
        if len(code_blocks) % 2 != 0:
            issues.append("ä»£ç å—æœªé—­åˆ")

        return {
            "is_valid": len(issues) == 0,
            "issues": issues,
            "score": max(0, 100 - len(issues) * 20)  # ç®€å•è¯„åˆ†
        }
```

**CRA æ–‡æ¡£å¤„ç†å®Œæ•´ç¤ºä¾‹ï¼š**

```python
# CRA æ–‡æ¡£ä¼˜åŒ–å®Œæ•´æµç¨‹
from backend.src.document_processor.pdf_extractor import PDFTextExtractor
from backend.src.document_processor.content_classifier import TaxContentClassifier
from backend.src.document_processor.skill_generator import SkillGenerator
from backend.src.document_processor.markdown_optimizer import CRADocumentOptimizer

# 1. PDF æå–
extractor = PDFTextExtractor("t4012-24e.pdf")
extracted_data = extractor.extract_all()

# 2. å†…å®¹åˆ†ç±»
classifier = TaxContentClassifier()
classified_contents = classifier.classify_content(extracted_data)

# 3. ç”Ÿæˆ Skills
skill_generator = SkillGenerator("backend/src/skills")
skill_files = skill_generator.generate_skills(classified_contents)

# 4. ä¼˜åŒ– Markdown æ ¼å¼
optimizer = CRADocumentOptimizer()
for skill_file in skill_files:
    with open(skill_file, 'r', encoding='utf-8') as f:
        content = f.read()

    # æå– YAML Front Matter å’Œ Markdown å†…å®¹
    parts = content.split('---', 2)
    if len(parts) >= 3:
        yaml_part = parts[1]
        markdown_part = parts[2].strip()

        # ä¼˜åŒ– Markdown å†…å®¹
        optimized_markdown = optimizer.optimize_cra_content(
            markdown_part,
            source_file="t4012-24e.pdf",
            document_type="cra_tax_guide"
        )

        # é‡æ–°ç»„åˆ
        optimized_content = f"---\n{yaml_part}\n---\n\n{optimized_markdown}"

        # ä¿å­˜ä¼˜åŒ–åçš„æ–‡ä»¶
        with open(skill_file, 'w', encoding='utf-8') as f:
            f.write(optimized_content)

print(f"âœ… å·²ä¼˜åŒ– {len(skill_files)} ä¸ª CRA Skill æ–‡ä»¶")
```

**é›†æˆåˆ° MVP ç³»ç»Ÿï¼š**

```python
# ä¸ç°æœ‰ MVP ç³»ç»Ÿé›†æˆ
from mvp.skill_loader import SkillLoader

# éªŒè¯ç”Ÿæˆçš„ Skills
loader = SkillLoader("backend/src/skills")
skills = loader.get_all_skills_metadata()

print(f"ğŸ“š åŠ è½½äº† {len(skills)} ä¸ª Skills")

# æµ‹è¯•æŠ€èƒ½è·¯ç”±
from mvp.skill_router import SkillRouter

router = SkillRouter()
test_queries = [
    "èµ„æœ¬æ”¶ç›Šå¦‚ä½•è®¡ç®—ï¼Ÿ",
    "å°ä¼ä¸šç¨åŠ¡æŠµæ‰£æœ‰å“ªäº›ï¼Ÿ",
    "RRSP çš„è´¡çŒ®é™é¢æ˜¯å¤šå°‘ï¼Ÿ"
]

for query in test_queries:
    result = router.route(query, skills)
    print(f"é—®é¢˜: {query}")
    print(f"åŒ¹é…æŠ€èƒ½: {result['matched_skills']}")
    print(f"ç½®ä¿¡åº¦: {result['confidence']}\n")
```

## æµ‹è¯•éªŒè¯

### 1. æ¸…ç†åŠŸèƒ½æµ‹è¯•

```python
dirty_md = """ä»¥ä¸‹æ˜¯æå–çš„å†…å®¹ï¼š

# æ ‡é¢˜

å†…å®¹...


---
---
---

æ›´å¤šå†…å®¹"""

cleaned = optimizer._clean_content(dirty_md)
assert "ä»¥ä¸‹æ˜¯æå–çš„å†…å®¹" not in cleaned
assert cleaned.count("---") == 1
```

### 2. è¡¨æ ¼ä¿®å¤æµ‹è¯•

```python
broken_table = """
| åˆ—1|åˆ—2 |
|---|---|
|æ•°æ®1 | æ•°æ®2|
"""

fixed = optimizer._fix_tables(broken_table)
assert "| åˆ—1 | åˆ—2 |" in fixed
```

### 3. å…ƒæ•°æ®ç”Ÿæˆæµ‹è¯•

```python
markdown = "# æµ‹è¯•æ–‡æ¡£\n\nè¿™æ˜¯å†…å®¹"
metadata = optimizer._generate_metadata(markdown, "test.pdf", "generic")

assert metadata["title"] == "æµ‹è¯•æ–‡æ¡£"
assert metadata["source"] == "test.pdf"
assert "created_at" in metadata
```

### 4. è´¨é‡éªŒè¯æµ‹è¯•

```python
# é«˜è´¨é‡æ–‡æ¡£
good_md = "# æ ‡é¢˜\n\n## ç« èŠ‚\n\nå†…å®¹å¾ˆé•¿å¾ˆé•¿..."
quality = optimizer.validate_quality(good_md)
assert quality["is_valid"] == True
assert quality["score"] >= 80

# ä½è´¨é‡æ–‡æ¡£
bad_md = "short"
quality = optimizer.validate_quality(bad_md)
assert quality["is_valid"] == False
```

## æ³¨æ„äº‹é¡¹

**å…ƒæ•°æ®æ ‡å‡†åŒ–ï¼š**
- ä½¿ç”¨ YAML Front Matter ç¬¦åˆ Jekyll/Hugo ç­‰æ ‡å‡†
- ä¾¿äºåç»­æ£€ç´¢å’Œè¿‡æ»¤

**æ€§èƒ½ä¼˜åŒ–ï¼š**
- ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æ—¶æ³¨æ„æ€§èƒ½
- å¤§æ–‡æ¡£åˆ†å—å¤„ç†
- ç¼“å­˜å¸¸ç”¨æ“ä½œç»“æœ

**å¯æ‰©å±•æ€§ï¼š**
- é¢„ç•™è‡ªå®šä¹‰æ¸…ç†è§„åˆ™æ¥å£
- æ”¯æŒæ’ä»¶å¼æ ¼å¼åŒ–è§„åˆ™
- å…è®¸è‡ªå®šä¹‰å…ƒæ•°æ®å­—æ®µ

**LLM å¢å¼ºï¼ˆå¯é€‰ï¼‰ï¼š**
ä½¿ç”¨ LLM ç”Ÿæˆæ›´å¥½çš„æ‘˜è¦å’Œå…³é”®è¯ï¼š
```python
def _generate_summary_with_llm(self, markdown: str) -> str:
    # è°ƒç”¨ GLM-4-Flash ç”Ÿæˆæ‘˜è¦
    prompt = f"è¯·ç”¨ä¸€å¥è¯æ€»ç»“ä»¥ä¸‹æ–‡æ¡£çš„æ ¸å¿ƒå†…å®¹ï¼š\n\n{markdown[:1000]}"
    # ... LLM è°ƒç”¨
    return summary
```

## ä¾èµ–å…³ç³»

**æ–°å¢ä¾èµ–ï¼š**
```toml
# å·²åœ¨ pyproject.toml ä¸­é…ç½®
PyMuPDF>=1.24.0          # PDF å¤„ç†
PyYAML>=6.0             # YAML å¤„ç†
```

**å‰ç½®ä»»åŠ¡ï¼š**
- ä»»åŠ¡05ï¼šPDF æ–‡æœ¬æå–æ¨¡å—
- ä»»åŠ¡06ï¼šå†…å®¹åˆ†ç±»æ¨¡å—
- ä»»åŠ¡07ï¼šSkill ç”Ÿæˆæ¨¡å—

**åç½®ä»»åŠ¡ï¼š**
- é›†æˆåˆ°åç«¯ API ç³»ç»Ÿ
- ä¸ MVP ç³»ç»Ÿå…¼å®¹æ€§æµ‹è¯•
- CRA æ–‡æ¡£æ›´æ–°ç»´æŠ¤æµç¨‹

## ä¸ Skill Seeker çš„å…³ç³»

**æŠ€æœ¯æ ˆç»§æ‰¿ï¼š**
- åŸºäº Skill Seeker çš„ PyMuPDF å¤„ç†æ–¹æ¡ˆ
- ä¿ç•™æ–‡æœ¬æå–å’Œè¡¨æ ¼æ£€æµ‹çš„æ ¸å¿ƒé€»è¾‘
- é€‚é… CRA ç¨åŠ¡æ–‡æ¡£çš„ç‰¹æ®Šéœ€æ±‚

**åŠŸèƒ½å¢å¼ºï¼š**
- CRA ä¸“ç”¨å†…å®¹æ¸…ç†å’Œæ ¼å¼åŒ–
- MVP Skill ç³»ç»Ÿå…¼å®¹æ€§
- ç¨åŠ¡æœ¯è¯­æ™ºèƒ½è¯†åˆ«å’Œé«˜äº®
- åŒè¯­å†…å®¹å¤„ç†æ”¯æŒ

**è¾“å‡ºæ ¼å¼ç»Ÿä¸€ï¼š**
- ç”Ÿæˆçš„ Skills å®Œå…¨å…¼å®¹ç°æœ‰ MVP ç³»ç»Ÿ
- æ”¯æŒ skill_loader.py å’Œ skill_router.py
- æä¾›ç»Ÿä¸€çš„ç¨åŠ¡çŸ¥è¯†åº“æ¥å£

è¿™ä¸ªä¼˜åŒ–å™¨å®Œæˆäº† CRA æ–‡æ¡£å¤„ç†çš„æœ€åä¸€å…¬é‡Œï¼Œç¡®ä¿ä»åŸå§‹ PDF åˆ°å¯ç”¨ Skill çš„æ•´ä¸ªæµç¨‹éƒ½èƒ½äº§å‡ºé«˜è´¨é‡ã€æ ‡å‡†åŒ–çš„çŸ¥è¯†åº“å†…å®¹ã€‚

## Skill_Seekers AI å¢å¼ºç»„ä»¶å®ç°

### AI æ¨¡æ¿å¢å¼ºå™¨

```python
class AITemplateEnhancer:
    """AI æ¨¡æ¿å¢å¼ºå™¨ï¼ˆé›†æˆ Skill_Seekers æŠ€æœ¯ï¼‰"""

    def __init__(self):
        self.claude_max_available = self._check_claude_max()
        self.enhancement_prompts = self._load_enhancement_prompts()

    def enhance_content(self, content: str, source_file: Optional[str],
                       document_type: str, enhancement_level: str = "comprehensive") -> str:
        """ä½¿ç”¨ AI å¢å¼ºå†…å®¹"""

        if not self.claude_max_available:
            print("âš ï¸ Claude Code Max ä¸å¯ç”¨ï¼Œè·³è¿‡ AI å¢å¼º")
            return content

        # æ ¹æ®å¢å¼ºçº§åˆ«é€‰æ‹©æç¤ºè¯
        prompt = self._select_enhancement_prompt(content, document_type, enhancement_level)

        try:
            enhanced_content = self._call_claude_max(prompt)
            return self._post_process_enhancement(enhanced_content, content)

        except Exception as e:
            print(f"âš ï¸ AI å¢å¼ºå¤±è´¥: {e}")
            return content

    def _check_claude_max(self) -> bool:
        """æ£€æŸ¥ Claude Code Max æ˜¯å¦å¯ç”¨"""
        try:
            import subprocess
            result = subprocess.run(
                ["claude-code-max", "--version"],
                capture_output=True,
                text=True,
                timeout=10
            )
            return result.returncode == 0
        except:
            return False

    def _load_enhancement_prompts(self) -> Dict[str, str]:
        """åŠ è½½å¢å¼ºæç¤ºè¯åº“"""
        return {
            "tax_guide_basic": """
ä½ æ˜¯ä¸€ä½åŠ æ‹¿å¤§ç¨åŠ¡ä¸“å®¶ï¼Œè¯·ä¼˜åŒ–ä»¥ä¸‹ç¨åŠ¡æ–‡æ¡£çš„ Markdown æ ¼å¼å’Œå†…å®¹ç»“æ„ï¼š

åŸå§‹å†…å®¹ï¼š
{content}

è¦æ±‚ï¼š
1. æ”¹å–„ Markdown æ ¼å¼çš„è§„èŒƒæ€§
2. ä¼˜åŒ–æ ‡é¢˜å±‚æ¬¡ç»“æ„
3. ä¿®å¤è¡¨æ ¼æ ¼å¼é—®é¢˜
4. å¢å¼ºåˆ—è¡¨çš„å¯è¯»æ€§
5. ç¡®ä¿è¯­æ³•æ­£ç¡®

è¯·è¿”å›ä¼˜åŒ–åçš„ Markdown å†…å®¹ï¼Œä¿æŒåŸæœ‰çš„æŠ€æœ¯ä¿¡æ¯ä¸å˜ã€‚
""",

            "tax_guide_comprehensive": """
ä½ æ˜¯ä¸€ä½èµ„æ·±çš„åŠ æ‹¿å¤§ç¨åŠ¡ä¸“å®¶ï¼Œè¯·å…¨é¢ä¼˜åŒ–ä»¥ä¸‹ç¨åŠ¡æ–‡æ¡£ï¼š

åŸå§‹å†…å®¹ï¼š
{content}

ä¼˜åŒ–è¦æ±‚ï¼š
1. **æ ¼å¼ä¼˜åŒ–**ï¼š
   - è§„èŒƒåŒ– Markdown è¯­æ³•
   - ä¼˜åŒ–æ ‡é¢˜å±‚æ¬¡ç»“æ„
   - ä¿®å¤è¡¨æ ¼å’Œåˆ—è¡¨æ ¼å¼
   - æ”¹å–„ä»£ç å—æ ¼å¼

2. **å†…å®¹å¢å¼º**ï¼š
   - æ·»åŠ å®ç”¨çš„æ“ä½œæ­¥éª¤
   - æä¾›å…·ä½“çš„è®¡ç®—ç¤ºä¾‹
   - åŒ…å«å¸¸è§é—®é¢˜è§£ç­”
   - æ·»åŠ ç¨åŠ¡å°è´´å£«

3. **ç»“æ„ä¼˜åŒ–**ï¼š
   - æ·»åŠ æ¸…æ™°çš„å¯¼èˆª
   - ç”Ÿæˆå†…å®¹æ‘˜è¦
   - åˆ›å»ºå¿«é€Ÿå‚è€ƒéƒ¨åˆ†
   - ä¼˜åŒ–ç« èŠ‚ç»„ç»‡

4. **ä¸“ä¸šæ€§æå‡**ï¼š
   - ä¿æŒæŠ€æœ¯å‡†ç¡®æ€§
   - ä½¿ç”¨ä¸“ä¸šæœ¯è¯­
   - å¼•ç”¨ç›¸å…³æ³•è§„
   - æä¾›å®ç”¨å»ºè®®

è¯·è¿”å›å…¨é¢ä¼˜åŒ–åçš„ Markdown å†…å®¹ã€‚
""",

            "calculation_example": """
è¯·ä¼˜åŒ–ä»¥ä¸‹ç¨åŠ¡è®¡ç®—ç¤ºä¾‹çš„å‘ˆç°æ–¹å¼ï¼š

åŸå§‹å†…å®¹ï¼š
{content}

ä¼˜åŒ–è¦æ±‚ï¼š
1. æ”¹è¿› Markdown è¡¨æ ¼æ ¼å¼
2. æ·»åŠ æ­¥éª¤è¯´æ˜
3. å¢å¼ºå¯è¯»æ€§
4. ç¡®ä¿è®¡ç®—å‡†ç¡®æ€§
5. æ·»åŠ ç»“æœè§£é‡Š

è¯·è¿”å›ä¼˜åŒ–åçš„è®¡ç®—ç¤ºä¾‹ã€‚
""",

            "quick_reference": """
è¯·å°†ä»¥ä¸‹ç¨åŠ¡å†…å®¹è½¬æ¢ä¸ºå¿«é€Ÿå‚è€ƒæŒ‡å—ï¼š

åŸå§‹å†…å®¹ï¼š
{content}

è½¬æ¢è¦æ±‚ï¼š
1. æå–å…³é”®è¦ç‚¹
2. ä½¿ç”¨é¡¹ç›®ç¬¦å·åˆ—è¡¨
3. åŒ…å«é‡è¦æ—¥æœŸå’Œæˆªæ­¢æ—¶é—´
4. æ·»åŠ ç›¸å…³è¡¨æ ¼ç¼–å·
5. ç®€åŒ–è¯­è¨€è¡¨è¾¾

è¯·è¿”å›ç®€æ´æ˜äº†çš„å¿«é€Ÿå‚è€ƒæ ¼å¼ã€‚
"""
        }

    def _select_enhancement_prompt(self, content: str, document_type: str, level: str) -> str:
        """é€‰æ‹©åˆé€‚çš„å¢å¼ºæç¤ºè¯"""

        if level == "basic":
            prompt_template = self.enhancement_prompts["tax_guide_basic"]
        elif level == "comprehensive":
            prompt_template = self.enhancement_prompts["tax_guide_comprehensive"]
        elif document_type == "calculation_example":
            prompt_template = self.enhancement_prompts["calculation_example"]
        elif document_type == "quick_reference":
            prompt_template = self.enhancement_prompts["quick_reference"]
        else:
            prompt_template = self.enhancement_prompts["tax_guide_basic"]

        return prompt_template.format(content=content)

    def _call_claude_max(self, prompt: str) -> str:
        """è°ƒç”¨ Claude Code Max"""
        import subprocess

        try:
            result = subprocess.run([
                "claude-code-max",
                "--prompt", prompt,
                "--temperature", "0.3",
                "--max-tokens", "3000"
            ], capture_output=True, text=True, timeout=120)

            if result.returncode == 0:
                return result.stdout.strip()
            else:
                raise Exception(f"Claude Max å¤±è´¥: {result.stderr}")

        except subprocess.TimeoutExpired:
            raise Exception("Claude Max å¤„ç†è¶…æ—¶")

    def _post_process_enhancement(self, enhanced: str, original: str) -> str:
        """åå¤„ç†å¢å¼ºç»“æœ"""
        # ç¡®ä¿åŸºç¡€ç»“æ„å®Œæ•´æ€§
        if not enhanced.strip():
            return original

        # æ£€æŸ¥å…³é”®å…ƒç´ æ˜¯å¦ä¿ç•™
        original_elements = self._extract_key_elements(original)
        enhanced_elements = self._extract_key_elements(enhanced)

        # å¦‚æœå…³é”®å…ƒç´ ä¸¢å¤±ï¼Œå°è¯•ä¿®å¤
        missing_elements = original_elements - enhanced_elements
        if missing_elements:
            enhanced = self._restore_missing_elements(enhanced, original, missing_elements)

        return enhanced

    def _extract_key_elements(self, content: str) -> set:
        """æå–å…³é”®å…ƒç´ """
        elements = set()

        # æå–æ ‡é¢˜
        headings = re.findall(r"^#{1,6}\s+(.+)$", content, re.MULTILINE)
        elements.update(headings)

        # æå–ç¨åŠ¡æœ¯è¯­
        tax_terms = re.findall(r"\b(capital\s+gains|RRSP|GST/HST|tax\s+credits?)\b", content, re.IGNORECASE)
        elements.update(term.lower() for term in tax_terms)

        # æå–æ•°å€¼å’Œé‡‘é¢
        amounts = re.findall(r"\$[\d,]+\.?\d*", content)
        elements.update(amounts)

        # æå–ç™¾åˆ†æ¯”
        percentages = re.findall(r"\d+\.?\d*%", content)
        elements.update(percentages)

        return elements

    def _restore_missing_elements(self, enhanced: str, original: str, missing_elements: set) -> str:
        """æ¢å¤ç¼ºå¤±çš„å…³é”®å…ƒç´ """
        # ç®€åŒ–å®ç°ï¼šåœ¨å¢å¼ºå†…å®¹åæ·»åŠ ç¼ºå¤±å…ƒç´ 
        restored_content = enhanced

        if missing_elements:
            restored_content += "\n\n## ğŸ“‹ åŸå§‹å†…å®¹ä¸­çš„é‡è¦ä¿¡æ¯\n\n"
            for element in sorted(missing_elements):
                if element.startswith('$') or element.endswith('%'):
                    restored_content += f"- **{element}**\n"
                else:
                    restored_content += f"- {element}\n"

        return restored_content
```

### æ™ºèƒ½æ¨¡æ¿å¼•æ“

```python
class IntelligentTemplateEngine:
    """æ™ºèƒ½æ¨¡æ¿å¼•æ“ï¼ˆæ¥è‡ª Skill_Seekersï¼‰"""

    def __init__(self):
        self.templates = self._load_templates()
        self.structure_analyzer = DocumentStructureAnalyzer()

    def optimize_template(self, content: str, document_type: str) -> str:
        """ä¼˜åŒ–å†…å®¹æ¨¡æ¿"""

        # åˆ†ææ–‡æ¡£ç»“æ„
        structure = self.structure_analyzer.analyze(content)

        # é€‰æ‹©æœ€ä½³æ¨¡æ¿
        template = self._select_best_template(structure, document_type)

        # åº”ç”¨æ¨¡æ¿ä¼˜åŒ–
        optimized = self._apply_template_optimization(content, template, structure)

        return optimized

    def _load_templates(self) -> Dict[str, Dict]:
        """åŠ è½½æ¨¡æ¿é…ç½®"""
        return {
            "tax_guide": {
                "required_sections": ["æ¦‚è¿°", "ä¸»è¦å†…å®¹", "è®¡ç®—æ–¹æ³•", "ç¤ºä¾‹"],
                "optional_sections": ["æ³¨æ„äº‹é¡¹", "ç›¸å…³èµ„æº", "å¸¸è§é—®é¢˜"],
                "format_rules": {
                    "heading_style": "incremental",
                    "list_style": "bullet",
                    "table_style": "github"
                }
            },
            "calculation_example": {
                "required_sections": ["åœºæ™¯", "æ¡ä»¶", "æ­¥éª¤", "ç»“æœ"],
                "optional_sections": ["è¯´æ˜", "ç›¸å…³æ³•è§„"],
                "format_rules": {
                    "heading_style": "consistent",
                    "list_style": "numbered",
                    "table_style": "github"
                }
            },
            "quick_reference": {
                "required_sections": ["è¦ç‚¹", "æ—¥æœŸ", "è¡¨æ ¼"],
                "optional_sections": ["æ³¨æ„äº‹é¡¹", "èµ„æºé“¾æ¥"],
                "format_rules": {
                    "heading_style": "simple",
                    "list_style": "bullet",
                    "table_style": "simple"
                }
            }
        }

    def _select_best_template(self, structure: Dict, document_type: str) -> Dict:
        """é€‰æ‹©æœ€ä½³æ¨¡æ¿"""
        # åŸºäºæ–‡æ¡£ç»“æ„å’Œç±»å‹é€‰æ‹©æ¨¡æ¿
        if document_type in self.templates:
            return self.templates[document_type]

        # åŸºäºç»“æ„ç‰¹å¾è‡ªåŠ¨é€‰æ‹©
        if structure.get('has_calculations', False):
            return self.templates["calculation_example"]
        elif structure.get('section_count', 0) <= 3:
            return self.templates["quick_reference"]
        else:
            return self.templates["tax_guide"]

    def _apply_template_optimization(self, content: str, template: Dict, structure: Dict) -> str:
        """åº”ç”¨æ¨¡æ¿ä¼˜åŒ–"""

        optimized_content = content

        # 1. ä¼˜åŒ–æ ‡é¢˜ç»“æ„
        optimized_content = self._optimize_heading_structure(optimized_content, template)

        # 2. ä¼˜åŒ–åˆ—è¡¨æ ¼å¼
        optimized_content = self._optimize_lists(optimized_content, template)

        # 3. ä¼˜åŒ–è¡¨æ ¼æ ¼å¼
        optimized_content = self._optimize_tables(optimized_content, template)

        # 4. ç¡®ä¿å¿…éœ€ç« èŠ‚å­˜åœ¨
        optimized_content = self._ensure_required_sections(optimized_content, template)

        return optimized_content

    def _optimize_heading_structure(self, content: str, template: Dict) -> str:
        """ä¼˜åŒ–æ ‡é¢˜ç»“æ„"""
        lines = content.split('\n')
        optimized_lines = []

        current_level = 0
        heading_style = template['format_rules']['heading_style']

        for line in lines:
            heading_match = re.match(r'^(#{1,6})\s+(.+)$', line)
            if heading_match:
                markers, title = heading_match.groups()
                level = len(markers)

                if heading_style == "incremental":
                    # ç¡®ä¿æ ‡é¢˜é€’å¢
                    if level > current_level + 1:
                        level = current_level + 1
                    current_level = level
                elif heading_style == "consistent":
                    # ä¿æŒä¸€è‡´çš„æ ‡é¢˜å±‚çº§
                    if level == 1 and current_level > 0:
                        level = 2
                    current_level = level

                optimized_line = f"{'#' * level} {title}"
                optimized_lines.append(optimized_line)
            else:
                optimized_lines.append(line)

        return '\n'.join(optimized_lines)

    def _optimize_lists(self, content: str, template: Dict) -> str:
        """ä¼˜åŒ–åˆ—è¡¨æ ¼å¼"""
        list_style = template['format_rules']['list_style']
        lines = content.split('\n')
        optimized_lines = []

        for line in lines:
            if re.match(r'^\s*[-*+]\s+', line):
                if list_style == "numbered":
                    # è½¬æ¢ä¸ºæœ‰åºåˆ—è¡¨
                    number = self._get_list_number(line, lines)
                    optimized_line = re.sub(r'^\s*[-*+]\s+', f'{number}. ', line)
                    optimized_lines.append(optimized_line)
                else:
                    optimized_lines.append(line)
            elif re.match(r'^\s*\d+\.\s+', line):
                if list_style == "bullet":
                    # è½¬æ¢ä¸ºæ— åºåˆ—è¡¨
                    optimized_line = re.sub(r'^\s*\d+\.\s+', '- ', line)
                    optimized_lines.append(optimized_line)
                else:
                    optimized_lines.append(line)
            else:
                optimized_lines.append(line)

        return '\n'.join(optimized_lines)

    def _get_list_number(self, current_line: str, all_lines: List[str]) -> int:
        """è·å–åˆ—è¡¨ç¼–å·"""
        # ç®€åŒ–å®ç°ï¼šè®¡ç®—å‰é¢çš„åˆ—è¡¨é¡¹æ•°é‡
        list_count = 0
        for i, line in enumerate(all_lines):
            if line == current_line:
                break
            if re.match(r'^\s*\d+\.\s+', line):
                list_count += 1

        return list_count + 1

    def _optimize_tables(self, content: str, template: Dict) -> str:
        """ä¼˜åŒ–è¡¨æ ¼æ ¼å¼"""
        table_style = template['format_rules']['table_style']
        lines = content.split('\n')
        optimized_lines = []

        i = 0
        while i < len(lines):
            line = lines[i]

            if '|' in line:
                # æ£€æµ‹è¡¨æ ¼å¼€å§‹
                table_lines = []
                while i < len(lines) and ('|' in lines[i] or re.match(r'^\s*$', lines[i])):
                    table_lines.append(lines[i])
                    i += 1

                # ä¼˜åŒ–è¡¨æ ¼
                optimized_table = self._optimize_table_format(table_lines, table_style)
                optimized_lines.extend(optimized_table)
            else:
                optimized_lines.append(line)
                i += 1

        return '\n'.join(optimized_lines)

    def _optimize_table_format(self, table_lines: List[str], style: str) -> List[str]:
        """ä¼˜åŒ–è¡¨æ ¼æ ¼å¼"""
        # ç§»é™¤ç©ºè¡Œ
        table_lines = [line for line in table_lines if line.strip()]

        if not table_lines:
            return table_lines

        # ç¡®ä¿è¡¨æ ¼è¡Œæ ¼å¼æ­£ç¡®
        optimized_table = []
        for line in table_lines:
            if not line.strip().startswith('|'):
                line = '| ' + line
            if not line.strip().endswith('|'):
                line = line + ' |'
            optimized_table.append(line)

        # æ£€æŸ¥æ˜¯å¦æœ‰åˆ†éš”è¡Œ
        has_separator = any(re.match(r'^\s*\|[\s\-:|]+\|$', line) for line in optimized_table)

        if not has_separator and len(optimized_table) > 1:
            # åœ¨ç¬¬ä¸€è¡Œåæ·»åŠ åˆ†éš”è¡Œ
            first_line = optimized_table[0]
            columns = len(first_line.split('|')) - 2
            separator = '|' + ' --- |' * columns + ' |'
            optimized_table.insert(1, separator)

        return optimized_table

    def _ensure_required_sections(self, content: str, template: Dict) -> str:
        """ç¡®ä¿å¿…éœ€ç« èŠ‚å­˜åœ¨"""
        required_sections = template.get('required_sections', [])
        existing_headings = re.findall(r'^#{1,6}\s+(.+)$', content, re.MULTILINE)

        missing_sections = [section for section in required_sections if not any(section in heading for heading in existing_headings)]

        if missing_sections:
            # åœ¨å†…å®¹æœ«å°¾æ·»åŠ ç¼ºå¤±ç« èŠ‚
            content += "\n\n## ç¼ºå¤±ç« èŠ‚\n\n"
            for section in missing_sections:
                content += f"### {section}\n\n*æ­¤éƒ¨åˆ†éœ€è¦è¡¥å……å†…å®¹*\n\n"

        return content

class DocumentStructureAnalyzer:
    """æ–‡æ¡£ç»“æ„åˆ†æå™¨"""

    def analyze(self, content: str) -> Dict:
        """åˆ†ææ–‡æ¡£ç»“æ„"""
        structure = {
            'section_count': 0,
            'has_tables': False,
            'has_lists': False,
            'has_calculations': False,
            'heading_levels': set(),
            'estimated_length': len(content)
        }

        # åˆ†ææ ‡é¢˜
        headings = re.findall(r'^(#{1,6})\s+', content, re.MULTILINE)
        structure['section_count'] = len(headings)
        structure['heading_levels'] = set(len(h) for h in headings)

        # åˆ†æè¡¨æ ¼
        if '|' in content:
            structure['has_tables'] = True

        # åˆ†æåˆ—è¡¨
        if re.search(r'^\s*[-*+]\s+|^\s*\d+\.\s+', content, re.MULTILINE):
            structure['has_lists'] = True

        # åˆ†æè®¡ç®—
        if re.search(r'\$[\d,]+\.?\d*|\d+\.?\d*%', content):
            structure['has_calculations'] = True

        return structure
```

## Skill_Seekers é›†æˆä½¿ç”¨ç¤ºä¾‹

```python
# å®Œæ•´çš„ CRA æ–‡æ¡£ä¼˜åŒ–ç¤ºä¾‹
def optimize_cra_document_with_ai():
    """ä½¿ç”¨ AI å¢å¼ºçš„ CRA æ–‡æ¡£ä¼˜åŒ–"""

    # åˆ›å»ºå¢å¼ºç‰ˆä¼˜åŒ–å™¨
    optimizer = CRADocumentOptimizer()

    # é…ç½® AI å¢å¼º
    optimizer.ai_config.update({
        "enable_ai_enhancement": True,
        "enable_template_optimization": True,
        "use_claude_max": True
    })

    # ç¤ºä¾‹å†…å®¹
    sample_content = """
# Capital Gains

When you sell property you may have capital gains.

Calculate: Selling price minus cost base.

Rate: 50% inclusion rate.
"""

    # æ‰§è¡Œä¼˜åŒ–
    optimized_content = optimizer.optimize_cra_content(
        raw_markdown=sample_content,
        source_file="t4012-sample.pdf",
        document_type="tax_guide",
        enable_ai_enhancement=True
    )

    print("âœ… AI å¢å¼ºä¼˜åŒ–å®Œæˆ")
    print(f"ğŸ“Š å¤„ç†ç»Ÿè®¡: {optimizer.stats}")
    print("ğŸ“ ä¼˜åŒ–ç»“æœ:")
    print(optimized_content)

# æ‰¹é‡ä¼˜åŒ–ç¤ºä¾‹
def batch_optimize_cra_documents():
    """æ‰¹é‡ä¼˜åŒ– CRA æ–‡æ¡£"""

    optimizer = CRADocumentOptimizer()

    # æ¨¡æ‹Ÿå¤šä¸ªæ–‡æ¡£
    documents = [
        {"content": "Business income guide...", "type": "tax_guide"},
        {"content": "RRSP contribution rules...", "type": "quick_reference"},
        {"content": "Capital gains calculation...", "type": "calculation_example"}
    ]

    results = []
    for doc in documents:
        optimized = optimizer.optimize_cra_content(
            raw_markdown=doc["content"],
            document_type=doc["type"],
            enable_ai_enhancement=True
        )
        results.append(optimized)

    print(f"âœ… æ‰¹é‡ä¼˜åŒ–å®Œæˆï¼Œå¤„ç†äº† {len(results)} ä¸ªæ–‡æ¡£")
    print(f"ğŸ“Š æ€»è®¡ AI å¢å¼º: {optimizer.stats['ai_enhanced']}")
    print(f"ğŸ¯ æ¨¡æ¿ä¼˜åŒ–: {optimizer.stats['template_optimized']}")

    return results
```

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. ç¼“å­˜ç­–ç•¥

```python
class CachedOptimizer:
    """å¸¦ç¼“å­˜çš„ä¼˜åŒ–å™¨"""

    def __init__(self):
        self.optimizer = CRADocumentOptimizer()
        self.content_cache = {}
        self.cache_ttl = 3600  # 1å°æ—¶

    def optimize_with_cache(self, content: str, **kwargs) -> str:
        """ä½¿ç”¨ç¼“å­˜çš„ä¼˜åŒ–"""
        content_hash = hashlib.md5(content.encode()).hexdigest()

        # æ£€æŸ¥ç¼“å­˜
        if content_hash in self.content_cache:
            cached_result, timestamp = self.content_cache[content_hash]
            if time.time() - timestamp < self.cache_ttl:
                return cached_result

        # æ‰§è¡Œä¼˜åŒ–
        result = self.optimizer.optimize_cra_content(content, **kwargs)

        # ç¼“å­˜ç»“æœ
        self.content_cache[content_hash] = (result, time.time())

        return result
```

### 2. å¹¶è¡Œå¤„ç†

```python
class ParallelOptimizer:
    """å¹¶è¡Œä¼˜åŒ–å™¨"""

    def __init__(self, max_workers: int = 4):
        self.max_workers = max_workers
        self.optimizer = CRADocumentOptimizer()

    def optimize_batch_parallel(self, documents: List[Dict]) -> List[str]:
        """å¹¶è¡Œæ‰¹é‡ä¼˜åŒ–"""
        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:
            futures = []
            for doc in documents:
                future = executor.submit(
                    self.optimizer.optimize_cra_content,
                    doc["content"],
                    doc.get("source_file"),
                    doc.get("document_type", "tax_guide"),
                    doc.get("enable_ai_enhancement", True)
                )
                futures.append(future)

            results = [future.result() for future in futures]

        return results
```

## æµ‹è¯•éªŒè¯

### AI å¢å¼ºæ•ˆæœæµ‹è¯•

```python
def test_ai_enhancement_effectiveness():
    """æµ‹è¯• AI å¢å¼ºæ•ˆæœ"""

    optimizer = CRADocumentOptimizer()

    # æµ‹è¯•æ•°æ®
    test_cases = [
        {
            "name": "åŸºç¡€ç¨åŠ¡æŒ‡å—",
            "content": "Simple tax guide content...",
            "expected_improvements": ["structure", "readability", "completeness"]
        },
        {
            "name": "è®¡ç®—ç¤ºä¾‹",
            "content": "Basic calculation example...",
            "expected_improvements": ["format", "clarity", "accuracy"]
        }
    ]

    for test_case in test_cases:
        print(f"\nğŸ§ª æµ‹è¯•: {test_case['name']}")

        # ä¸ä½¿ç”¨ AI å¢å¼º
        basic_result = optimizer.optimize_cra_content(
            test_case["content"],
            enable_ai_enhancement=False
        )

        # ä½¿ç”¨ AI å¢å¼º
        enhanced_result = optimizer.optimize_cra_content(
            test_case["content"],
            enable_ai_enhancement=True
        )

        # å¯¹æ¯”åˆ†æ
        improvement_score = analyze_improvement(basic_result, enhanced_result)
        print(f"ğŸ“ˆ æ”¹è¿›è¯„åˆ†: {improvement_score:.2f}")
        print(f"âœ¨ å†…å®¹é•¿åº¦å˜åŒ–: {len(basic_result)} â†’ {len(enhanced_result)}")

def analyze_improvement(original: str, enhanced: str) -> float:
    """åˆ†ææ”¹è¿›æ•ˆæœ"""
    # ç®€åŒ–çš„æ”¹è¿›è¯„åˆ†ç®—æ³•
    score = 0.0

    # ç»“æ„æ”¹è¿›
    original_headings = len(re.findall(r'^#{1,6}', original, re.MULTILINE))
    enhanced_headings = len(re.findall(r'^#{1,6}', enhanced, re.MULTILINE))
    if enhanced_headings > original_headings:
        score += 0.2

    # åˆ—è¡¨æ”¹è¿›
    original_lists = len(re.findall(r'^\s*[-*+]|\d+\.', original, re.MULTILINE))
    enhanced_lists = len(re.findall(r'^\s*[-*+]|\d+\.', enhanced, re.MULTILINE))
    if enhanced_lists > original_lists:
        score += 0.2

    # å†…å®¹å®Œæ•´æ€§
    if len(enhanced) > len(original) * 1.2:
        score += 0.3

    # æ ¼å¼è§„èŒƒæ€§
    enhanced_format_score = check_markdown_format(enhanced)
    score += enhanced_format_score * 0.3

    return min(score, 1.0)
```

## ä¾èµ–å…³ç³»æ›´æ–°

**æ–°å¢ä¾èµ–ï¼š**
```toml
# Skill_Seekers AI å¢å¼ºä¾èµ–
anthropic>=0.7.0          # Claude APIï¼ˆå¤‡é€‰ï¼‰
openai>=1.0.0             # OpenAI APIï¼ˆå¤‡é€‰ï¼‰
subprocess>=3.8.0         # ç³»ç»Ÿè°ƒç”¨
hashlib                   # å†…å®¹å“ˆå¸Œ
threading                 # å¹¶è¡Œå¤„ç†

# Claude Code Maxï¼ˆå¤–éƒ¨å·¥å…·ï¼‰
# éœ€è¦å•ç‹¬å®‰è£… Claude Code Max å‘½ä»¤è¡Œå·¥å…·
```

**å·¥å…·ä¾èµ–ï¼š**
```bash
# å®‰è£… Claude Code Max
wget https://github.com/anthropics/claude-code-max/releases/latest/claude-code-max-linux
chmod +x claude-code-max-linux
sudo mv claude-code-max-linux /usr/local/bin/claude-code-max
```

**å‰ç½®ä»»åŠ¡ï¼š**
- ä»»åŠ¡05ï¼šPDF æ–‡æœ¬æå–æ¨¡å—
- ä»»åŠ¡06ï¼šå¢å¼ºå†…å®¹åˆ†ç±»æ¨¡å—
- ä»»åŠ¡07ï¼šAI å¢å¼ºæŠ€èƒ½ç”Ÿæˆæ¨¡å—

**åç½®ä»»åŠ¡ï¼š**
- é›†æˆæµ‹è¯•å’Œæ€§èƒ½éªŒè¯
- ä¸ MVP ç³»ç»Ÿçš„å®Œæ•´é›†æˆ
- ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²å’Œç›‘æ§

è¿™ä¸ªå¢å¼ºç‰ˆçš„ Markdown ä¼˜åŒ–å™¨é›†æˆäº† Skill_Seekers çš„å…ˆè¿›æŠ€æœ¯ï¼Œèƒ½å¤Ÿå°†åŸºç¡€çš„ CRA æ–‡æ¡£è½¬æ¢ä¸ºé«˜è´¨é‡ã€æ™ºèƒ½åŒ–çš„ç¨åŠ¡çŸ¥è¯†æŒ‡å—ï¼Œä¸º BlockMe ç³»ç»Ÿæä¾›ä¸“ä¸šçº§çš„å†…å®¹å¤„ç†èƒ½åŠ›ã€‚
