#!/usr/bin/env python3
"""
Stage 2: Content Classification

Classifies extracted content using dynamic semantic analysis with LLM.
Categories are dynamically generated by LLM based on document content.

Usage:
    # Semantic classification with GLM-4.6 via Direct API
    uv run python stage2_classify_content.py --extraction-id abc123

    # Force re-classification (ignore cache)
    uv run python stage2_classify_content.py --extraction-id abc123 --force

    # Custom cache directory
    uv run python stage2_classify_content.py --extraction-id abc123 --cache-dir /path/to/cache
"""

import argparse
import logging
import sys
from datetime import datetime
from pathlib import Path

# Add parent directory to path for imports
sys.path.insert(0, str(Path(__file__).parent))

from app.document_processor.content_classifier import QualityMetrics
from app.document_processor.pipeline_manager import CacheManager, PipelineStage
from app.document_processor.llm_cli_providers import get_provider

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# TOC data structures
class TOCEntry:
    """Table of Contents entry."""
    def __init__(self, level: int, title: str, page_number: int, char_start: int = None, char_end: int = None):
        self.level = level
        self.title = title
        self.page_number = page_number
        self.char_start = char_start
        self.char_end = char_end

class DocumentTOC:
    """Document Table of Contents structure."""
    def __init__(self, has_toc: bool = False, source: str = "generated"):
        self.has_toc = has_toc
        self.source = source
        self.entries = []
        self.max_level = 1

class DocumentAnalysis:
    """Document analysis result."""
    def __init__(self, classification, toc, total_chars: int, processing_time: float, model: str):
        self.classification = classification
        self.toc = toc
        self.total_chars = total_chars
        self.processing_time = processing_time
        self.model = model

class SmartClassification:
    """Classification result with dynamic category.

    Note: primary_category is now a string (dynamically generated by LLM),
    not a predefined enum.
    """
    def __init__(self, primary_category: str, confidence: float, reasoning: str):
        self.primary_category = primary_category  # Now a string, not enum
        self.confidence = confidence
        self.secondary_categories = []  # List of strings
        self.reasoning = reasoning
        self.method = "glm_api_semantic"
        self.quality_metrics = None
        self.semantic_tags = []  # List of semantic tags from LLM

def sample_document_content(content: str, max_chars: int = 30000) -> str:
    """
    æ™ºèƒ½é‡‡æ ·æ–‡æ¡£å†…å®¹ï¼Œç¡®ä¿è¦†ç›–æ–‡æ¡£å„éƒ¨åˆ†

    ç­–ç•¥ï¼š
    1. å¼€å¤´ 20% - é€šå¸¸åŒ…å« TOC å’Œæ¦‚è¿°
    2. ä¸­é—´é‡‡æ ·ç‚¹ - æ¯ 10% ä½ç½®å–ä¸€æ®µ
    3. ç»“å°¾ 10% - é€šå¸¸åŒ…å«é™„å½•å’Œç´¢å¼•
    """
    total_len = len(content)

    # å¦‚æœå†…å®¹è¾ƒçŸ­ï¼Œç›´æ¥è¿”å›
    if total_len <= max_chars:
        return content

    samples = []

    # å¼€å¤´ 20%ï¼ˆé€šå¸¸åŒ…å« TOCï¼‰
    head_size = min(int(total_len * 0.2), 8000)
    samples.append(("=== Document Start (first 20%) ===", content[:head_size]))

    # ä¸­é—´æ¯ 10% å– 2000 å­—ç¬¦
    for pct in [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]:
        start = int(total_len * pct)
        chunk_size = min(2000, total_len - start)
        samples.append((f"=== Content at {int(pct*100)}% position ===", content[start:start+chunk_size]))

    # ç»“å°¾ 10%
    tail_start = int(total_len * 0.9)
    tail_size = min(total_len - tail_start, 4000)
    samples.append(("=== Document End (last 10%) ===", content[tail_start:tail_start+tail_size]))

    # ç»„åˆé‡‡æ ·
    result = []
    for label, text in samples:
        result.append(f"\n{label}\n{text}")

    return "\n".join(result)


# Comprehensive analysis prompt for LLM
ANALYSIS_PROMPT = """Analyze this CRA tax document comprehensively.

Document Title: {title}
Document Length: {total_chars:,} characters

## Task 1: Classification
Classify the document's primary purpose and topics.

## Task 2: Document Structure (TOC)
Extract the document's table of contents by finding EXACT titles from the document text.

CRITICAL RULES:
1. Only include titles that appear VERBATIM in the document
2. Copy titles exactly as written - do not paraphrase or infer
3. Look for the actual "Table of Contents" section in the document first
4. If no TOC section exists, extract chapter/section headings exactly as they appear

Search for these patterns and copy them EXACTLY as written:
- "Chapter X â€“ ..." (copy the full title after the dash)
- "Part X â€“ ..." or "Section X â€“ ..."
- Lines in ALL CAPS that serve as headings
- Numbered sections like "1.1 Title"

DO NOT:
- Infer or guess what a chapter might be about
- Combine or rewrite titles
- Add content descriptions that don't exist in the document

## Task 3: Content Regions
Identify major content regions by province/jurisdiction and topic.
Canadian provinces: Ontario, Manitoba, Saskatchewan, British Columbia, Alberta, Quebec, Nova Scotia, New Brunswick, PEI, Newfoundland
Territories: Yukon, Northwest Territories, Nunavut
Federal: applies to all of Canada

## Task 4: Semantic Tags
Generate tags that would help users find this document.

Respond in this exact JSON format:
```json
{{
  "classification": {{
    "primary_category": "corporate_income_tax",
    "confidence": 0.95,
    "secondary_categories": ["provincial_tax_credits", "t2_return_guide"],
    "reasoning": "This is the official CRA T2 Corporation Income Tax Guide..."
  }},
  "toc": {{
    "has_toc": true,
    "entries": [
      {{"level": 1, "title": "Chapter 1 â€“ Page 1 of the T2 return", "page": 24, "source": "extracted"}},
      {{"level": 1, "title": "Chapter 2 â€“ Page 2 of the T2 return", "page": 31, "source": "extracted"}},
      {{"level": 2, "title": "Line 001 â€“ Business Number", "page": 39, "source": "extracted"}}
    ]
  }},
  "content_regions": [
    {{
      "region": "federal",
      "title": "T2 Return Instructions",
      "topics": ["T2 form pages", "general instructions", "filing requirements"],
      "estimated_start_percent": 0,
      "estimated_end_percent": 40
    }},
    {{
      "region": "ontario",
      "title": "Ontario Tax Credits",
      "topics": ["OIDMTC", "film tax credit", "book publishing credit"],
      "estimated_start_percent": 60,
      "estimated_end_percent": 70
    }}
  ],
  "semantic_tags": ["T2", "corporate tax", "CRA", "2024", "tax credits", "provincial tax"],
  "quality_assessment": {{
    "completeness": 0.95,
    "accuracy": 0.90,
    "relevance": 0.95,
    "clarity": 0.85,
    "practicality": 0.90
  }}
}}
```

Document content (sampled for analysis):
{content_sample}
"""


def parse_analysis_response(response: str) -> dict:
    """
    è§£æ LLM è¿”å›çš„ JSONï¼Œå¸¦å®¹é”™å¤„ç†
    """
    import json
    import re

    # æå– JSON å—
    json_match = re.search(r'```json\s*([\s\S]*?)\s*```', response)
    if json_match:
        json_str = json_match.group(1)
    else:
        # å°è¯•ç›´æ¥è§£æ
        json_match = re.search(r'\{[\s\S]*\}', response)
        json_str = json_match.group() if json_match else "{}"

    try:
        data = json.loads(json_str)
    except json.JSONDecodeError as e:
        logger.warning(f"JSON parse failed: {e}, using defaults")
        return get_default_analysis()

    return validate_and_normalize(data)


def safe_float(value, default: float = 0.5) -> float:
    """
    Safely convert a value to float, handling common LLM response formats.

    Handles:
    - Numeric types (int, float)
    - Numeric strings ("0.85", "85")
    - Percentage strings ("85%", "0.85%")
    - Word values ("high", "medium", "low")
    - Invalid values (None, empty string, etc.)

    Args:
        value: Value to convert
        default: Default value if conversion fails

    Returns:
        Float value between 0 and 1
    """
    if value is None:
        return default

    # Already a number
    if isinstance(value, (int, float)):
        result = float(value)
        # Normalize if > 1 (assume percentage)
        if result > 1:
            result = result / 100
        return max(0.0, min(1.0, result))

    # String handling
    if isinstance(value, str):
        value = value.strip().lower()

        # Empty string
        if not value:
            return default

        # Word values
        word_map = {
            'high': 0.85,
            'medium': 0.6,
            'med': 0.6,
            'low': 0.3,
            'very high': 0.95,
            'very low': 0.15,
            'none': 0.0,
            'n/a': default,
        }
        if value in word_map:
            return word_map[value]

        # Handle percentage
        is_percentage = '%' in value
        value = value.replace('%', '').strip()

        try:
            result = float(value)
            # If original had % or value > 1, treat as percentage
            if is_percentage or result > 1:
                result = result / 100
            return max(0.0, min(1.0, result))
        except ValueError:
            return default

    return default


def get_default_analysis() -> dict:
    """è¿”å›é»˜è®¤åˆ†æç»“æ„"""
    return {
        "classification": {
            "primary_category": "general_tax_document",
            "confidence": 0.5,
            "secondary_categories": [],
            "reasoning": "Unable to parse LLM response, using defaults"
        },
        "toc": {
            "has_toc": False,
            "entries": []
        },
        "content_regions": [],
        "semantic_tags": [],
        "quality_assessment": {
            "completeness": 0.5,
            "accuracy": 0.5,
            "relevance": 0.5,
            "clarity": 0.5,
            "practicality": 0.5
        }
    }


def validate_and_normalize(data: dict) -> dict:
    """éªŒè¯å¹¶è§„èŒƒåŒ–è§£æçš„æ•°æ®"""
    defaults = get_default_analysis()

    # éªŒè¯ classification
    classification = data.get("classification", {})
    if not isinstance(classification, dict):
        classification = defaults["classification"]
    else:
        classification = {
            "primary_category": classification.get("primary_category", defaults["classification"]["primary_category"]),
            "confidence": safe_float(classification.get("confidence"), 0.5),
            "secondary_categories": classification.get("secondary_categories", []),
            "reasoning": classification.get("reasoning", "")
        }

    # éªŒè¯ toc
    toc = data.get("toc", {})
    if not isinstance(toc, dict):
        toc = defaults["toc"]
    else:
        entries = toc.get("entries", [])
        if not isinstance(entries, list):
            entries = []
        # è§„èŒƒåŒ–æ¯ä¸ª entry
        normalized_entries = []
        for entry in entries:
            if isinstance(entry, dict):
                normalized_entries.append({
                    "level": int(entry.get("level", 1)),
                    "title": str(entry.get("title", "")),
                    "page": entry.get("page")
                })
        toc = {
            "has_toc": len(normalized_entries) > 0,
            "entries": normalized_entries
        }

    # éªŒè¯ content_regions
    content_regions = data.get("content_regions", [])
    if not isinstance(content_regions, list):
        content_regions = []
    normalized_regions = []
    for region in content_regions:
        if isinstance(region, dict):
            normalized_regions.append({
                "region": str(region.get("region", "unknown")),
                "title": str(region.get("title", "")),
                "topics": region.get("topics", []),
                "estimated_start_percent": region.get("estimated_start_percent", 0),
                "estimated_end_percent": region.get("estimated_end_percent", 100)
            })
    content_regions = normalized_regions

    # éªŒè¯ semantic_tags
    semantic_tags = data.get("semantic_tags", [])
    if not isinstance(semantic_tags, list):
        semantic_tags = []

    # éªŒè¯ quality_assessment
    quality = data.get("quality_assessment", {})
    if not isinstance(quality, dict):
        quality = defaults["quality_assessment"]
    else:
        quality = {
            "completeness": safe_float(quality.get("completeness"), 0.5),
            "accuracy": safe_float(quality.get("accuracy"), 0.5),
            "relevance": safe_float(quality.get("relevance"), 0.5),
            "clarity": safe_float(quality.get("clarity"), 0.5),
            "practicality": safe_float(quality.get("practicality"), 0.5)
        }

    return {
        "classification": classification,
        "toc": toc,
        "content_regions": content_regions,
        "semantic_tags": semantic_tags,
        "quality_assessment": quality
    }


def classify_with_glm_api(content: str, title: str = "") -> tuple[dict, float]:
    """Use GLM API to comprehensively analyze document.

    Returns:
        tuple: (analysis_dict, processing_time)
            - analysis_dict contains: classification, toc, content_regions, semantic_tags, quality_assessment
    """
    import time
    start_time = time.time()

    # Get GLM API provider (use glm-4-plus for better analysis)
    provider = get_provider('glm-api')
    if not provider or not provider.is_available():
        raise ValueError("GLM API provider not available. Please check GLM_API_KEY environment variable.")

    # Smart sample the document content
    content_sample = sample_document_content(content)
    logger.info(f"Sampled {len(content_sample):,} chars from {len(content):,} total chars")

    # Prepare comprehensive analysis prompt
    prompt = ANALYSIS_PROMPT.format(
        title=title,
        total_chars=len(content),
        content_sample=content_sample
    )

    try:
        # Call GLM API
        logger.info("Calling GLM API for comprehensive analysis...")
        response = provider.parse_output(prompt, "")
        logger.info(f"Received response: {len(response)} chars")

        # Parse and validate response
        analysis = parse_analysis_response(response)

        processing_time = time.time() - start_time
        return analysis, processing_time

    except Exception as e:
        logger.error(f"GLM API analysis failed: {e}")
        processing_time = time.time() - start_time
        return get_default_analysis(), processing_time


def classify_content(
    extraction_id: str,
    force: bool = False,
    cache_dir: Path = None,
    max_chunk_size: int = 300_000
) -> dict:
    """
    Classify extracted content using GLM-4.6 semantic analysis.

    Categories are dynamically generated by LLM based on document content.

    Args:
        extraction_id: Extraction cache hash ID
        force: Force re-classification even if cached
        cache_dir: Cache directory path
        max_chunk_size: Maximum chunk size for intelligent chunking

    Returns:
        Classification data dict
    """
    # Initialize cache manager
    cache_mgr = CacheManager(cache_dir)

    print(f"\n{'='*60}")
    print(f"Stage 2: Content Classification")
    print(f"{'='*60}")
    print(f"Extraction ID: {extraction_id}")

    print(f"Method: GLM-4.6 via Direct API (Dynamic Classification)")

    # Load extraction data
    extraction_data = cache_mgr.load_cache(PipelineStage.EXTRACTION, extraction_id)
    if not extraction_data:
        print(f"âŒ Error: Extraction cache not found for ID: {extraction_id}")
        print(f"   Expected: {cache_mgr.get_cache_path(PipelineStage.EXTRACTION, extraction_id)}")
        print(f"\nğŸ’¡ Run stage1_extract_pdf.py first")
        return None

    total_text = extraction_data.get("total_text", "")
    print(f"Loaded extraction: {len(total_text):,} chars from {extraction_data.get('processed_pages')} pages")

    # Check classification cache
    if not force:
        cached_classification = cache_mgr.load_cache(PipelineStage.CLASSIFICATION, extraction_id)
        if cached_classification:
            print(f"\nâœ… Found cached classification: {cache_mgr.get_cache_path(PipelineStage.CLASSIFICATION, extraction_id)}")
            print(f"   Category: {cached_classification.get('primary_category')}")
            print(f"   Confidence: {cached_classification.get('confidence'):.2f}")
            print(f"   Cached at: {cached_classification.get('classification_time')}")
            print("\nğŸ’¡ Use --force to re-classify")
            return cached_classification

    # Classify content with GLM-4.6
    print(f"\nğŸ§  Analyzing document with GLM-4.6 via Direct API...")
    print(f"   This will take ~{len(total_text) // 1000 * 1 // 60} minutes for {len(total_text):,} chars")
    print(f"   Using GLM API for dynamic document classification...")

    try:
        pdf_title = extraction_data.get('pdf_path', '').split('/')[-1]

        # Perform comprehensive document analysis using GLM API
        analysis, processing_time = classify_with_glm_api(
            content=total_text,
            title=pdf_title
        )

        # Extract components from analysis
        classification = analysis["classification"]
        toc = analysis["toc"]
        content_regions = analysis["content_regions"]
        semantic_tags = analysis["semantic_tags"]
        quality = analysis["quality_assessment"]

        # Calculate overall score and grade from quality metrics
        quality_values = [quality["completeness"], quality["accuracy"],
                        quality["relevance"], quality["clarity"], quality["practicality"]]
        overall_score = sum(quality_values) / len(quality_values)
        if overall_score >= 0.9:
            quality_grade = "A"
        elif overall_score >= 0.8:
            quality_grade = "B"
        elif overall_score >= 0.7:
            quality_grade = "C"
        else:
            quality_grade = "D"

        # Prepare classification data with all new fields
        classification_data = {
            "primary_category": classification["primary_category"],
            "confidence": classification["confidence"],
            "secondary_categories": [
                {
                    "category": cat,
                    "confidence": classification["confidence"] * 0.8
                }
                for cat in classification.get("secondary_categories", [])
            ],
            "reasoning": classification.get("reasoning", ""),
            "semantic_tags": semantic_tags,
            "method": "glm_api_comprehensive",
            "model": "glm-4-plus",
            "processing_time": processing_time,

            # TOC structure for Stage 3
            "toc": {
                "has_toc": toc["has_toc"],
                "source": "llm_extracted",
                "max_level": max((e["level"] for e in toc["entries"]), default=1),
                "entries": [
                    {
                        "level": entry["level"],
                        "title": entry["title"],
                        "page_number": entry.get("page"),
                        "char_start": None,
                        "char_end": None
                    }
                    for entry in toc["entries"]
                ]
            },

            # Content regions for Stage 5
            "content_regions": content_regions,

            # Quality metrics from LLM
            "quality_metrics": {
                "completeness": quality["completeness"],
                "accuracy": quality["accuracy"],
                "relevance": quality["relevance"],
                "clarity": quality["clarity"],
                "practicality": quality["practicality"],
                "overall_score": overall_score,
                "quality_grade": quality_grade
            },

            "classification_time": datetime.now().isoformat()
        }

    except Exception as e:
        logger.error(f"GLM API classification failed: {e}")
        raise

    # Save to cache
    print(f"\nğŸ’¾ Saving classification to cache...")
    cache_path = cache_mgr.save_cache(
        PipelineStage.CLASSIFICATION,
        extraction_id,
        classification_data,
        metadata={
            "primary_category": classification_data["primary_category"],
            "confidence": classification_data["confidence"]
        }
    )

    print(f"\nâœ… Classification complete!")
    print(f"   Primary category: {classification_data['primary_category']}")
    print(f"   Confidence: {classification_data['confidence']:.2f}")
    print(f"   Method: {classification_data.get('method', 'gemini_semantic')}")
    print(f"   Model: {classification_data.get('model', 'N/A')}")
    print(f"   Processing_time: {classification_data.get('processing_time', 0):.1f}s")
    if 'reasoning' in classification_data:
        print(f"   Reasoning: {classification_data['reasoning'][:100]}...")
    print(f"   Cache: {cache_path}")

    # Show quality metrics
    qm = classification_data.get('quality_metrics', {})
    print(f"\nğŸ“Š Quality Metrics:")
    print(f"   Completeness: {qm.get('completeness', 0):.2f}")
    print(f"   Accuracy: {qm.get('accuracy', 0):.2f}")
    print(f"   Relevance: {qm.get('relevance', 0):.2f}")
    print(f"   Clarity: {qm.get('clarity', 0):.2f}")
    print(f"   Practicality: {qm.get('practicality', 0):.2f}")
    print(f"   Overall score: {qm.get('overall_score', 0):.2f} ({qm.get('quality_grade', 'N/A')})")

    # Show TOC structure
    toc_data = classification_data.get('toc', {})
    print(f"\nğŸ“‹ Document Structure (TOC):")
    print(f"   Has TOC: {toc_data.get('has_toc', False)}")
    print(f"   Source: {toc_data.get('source', 'N/A')}")
    print(f"   Max Level: {toc_data.get('max_level', 0)}")
    print(f"   Total Entries: {len(toc_data.get('entries', []))}")

    if toc_data.get('entries'):
        print(f"\n   Structure Preview:")
        for i, entry in enumerate(toc_data['entries'][:10]):  # Show first 10
            indent = "  " * (entry['level'] - 1)
            page_num = entry.get('page_number') or entry.get('page', 'N/A')
            print(f"   {indent}L{entry['level']}: {entry['title']} (p.{page_num})")
        if len(toc_data['entries']) > 10:
            print(f"   ... and {len(toc_data['entries']) - 10} more entries")

    # Show content regions
    regions = classification_data.get('content_regions', [])
    print(f"\nğŸ—ºï¸ Content Regions: {len(regions)} identified")
    for region in regions[:8]:  # Show first 8
        topics = ", ".join(region.get('topics', [])[:3])
        pct_range = f"{region.get('estimated_start_percent', 0)}-{region.get('estimated_end_percent', 100)}%"
        print(f"   [{region.get('region', 'unknown')}] {region.get('title', 'N/A')} ({pct_range})")
        if topics:
            print(f"      Topics: {topics}")
    if len(regions) > 8:
        print(f"   ... and {len(regions) - 8} more regions")

    # Show semantic tags
    tags = classification_data.get('semantic_tags', [])
    if tags:
        print(f"\nğŸ·ï¸ Semantic Tags: {', '.join(tags[:10])}")
        if len(tags) > 10:
            print(f"   ... and {len(tags) - 10} more tags")

    print(f"\nğŸ’¡ Next step: uv run python stage3_chunk_content.py --extraction-id {extraction_id}")

    return classification_data


def main():
    parser = argparse.ArgumentParser(
        description='Stage 2: Classify extracted content using dynamic semantic analysis',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Semantic classification with GLM-4.6 via Direct API
  python stage2_classify_content.py --extraction-id abc123

  # Force re-classification (ignore cache)
  python stage2_classify_content.py --extraction-id abc123 --force

  # List available extractions
  python -c "from app.document_processor.pipeline_manager import CacheManager; \\
             [print(f'{p[\"content_hash\"]}: {p[\"pdf_path\"]}') \\
              for p in CacheManager().list_cached_pdfs()]"
        """
    )

    parser.add_argument(
        '--extraction-id',
        type=str,
        required=True,
        help='Extraction cache hash ID (from stage1)'
    )

    parser.add_argument(
        '--force',
        action='store_true',
        help='Force re-classification even if cached'
    )


    parser.add_argument(
        '--max-chunk-size',
        type=int,
        default=300_000,
        help='Maximum chunk size in characters (default: 300000)'
    )

    parser.add_argument(
        '--cache-dir',
        type=Path,
        help='Cache directory (default: backend/cache/)'
    )

    args = parser.parse_args()

    # Classify content
    try:
        classification_data = classify_content(
            args.extraction_id,
            force=args.force,
            cache_dir=args.cache_dir,
            max_chunk_size=args.max_chunk_size
        )

        if classification_data is None:
            return 1

        return 0

    except Exception as e:
        print(f"\nâŒ Classification failed: {e}")
        logger.exception("Classification failed")
        return 1


if __name__ == '__main__':
    sys.exit(main())
