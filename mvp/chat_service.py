"""
Chat Service - ä½¿ç”¨ GLM-4.6 ç”Ÿæˆå›ç­”
"""
import os
from typing import List
from zhipuai import ZhipuAI
from skill_loader import Skill


class ChatService:
    """èŠå¤©æœåŠ¡ï¼Œä½¿ç”¨ GLM-4.6 ç”Ÿæˆå›ç­”"""

    def __init__(self, api_key: str = None):
        self.api_key = api_key or os.getenv("GLM_API_KEY")
        if not self.api_key:
            raise ValueError("æœªæ‰¾åˆ° GLM_API_KEY")

        self.client = ZhipuAI(api_key=self.api_key)
        # GLM-4.6 å¯é€‰æ¨¡å‹ï¼šglm-4-flash (å…è´¹), glm-4-plus (æ›´å¼º)
        self.model = "glm-4-flash"

    def generate_answer(
        self,
        user_query: str,
        loaded_skills: List[Skill] = None
    ) -> str:
        """
        ç”Ÿæˆå›ç­”

        Args:
            user_query: ç”¨æˆ·é—®é¢˜
            loaded_skills: åŠ è½½çš„ Skillsï¼ˆæä¾›çŸ¥è¯†ä¸Šä¸‹æ–‡ï¼‰

        Returns:
            LLM ç”Ÿæˆçš„å›ç­”
        """
        # æ„å»ºçŸ¥è¯†ä¸Šä¸‹æ–‡
        knowledge_context = self._build_knowledge_context(loaded_skills)

        # æ„å»ºæ¶ˆæ¯
        messages = []

        if knowledge_context:
            messages.append({
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¨åŠ¡çŸ¥è¯†åŠ©æ‰‹ã€‚è¯·åŸºäºæä¾›çš„çŸ¥è¯†å†…å®¹å‡†ç¡®å›ç­”ç”¨æˆ·é—®é¢˜ã€‚"
            })
            messages.append({
                "role": "user",
                "content": f"{knowledge_context}\n\n---\n\nç”¨æˆ·é—®é¢˜ï¼š{user_query}"
            })
        else:
            messages.append({
                "role": "system",
                "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„ç¨åŠ¡çŸ¥è¯†åŠ©æ‰‹ã€‚"
            })
            messages.append({
                "role": "user",
                "content": user_query
            })

        # è°ƒç”¨ GLM API
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=messages,
                max_tokens=1024,
                temperature=0.7
            )

            answer = response.choices[0].message.content

            print(f"\nğŸ’¬ GLM-4.6 å›ç­”:")
            print(f"{answer}\n")

            return answer

        except Exception as e:
            error_msg = f"âŒ ç”Ÿæˆå›ç­”å¤±è´¥: {e}"
            print(error_msg)
            return error_msg

    def _build_knowledge_context(self, loaded_skills: List[Skill]) -> str:
        """æ„å»ºçŸ¥è¯†ä¸Šä¸‹æ–‡"""
        if not loaded_skills:
            return ""

        context_parts = ["# ç›¸å…³çŸ¥è¯†\n"]

        for skill in loaded_skills:
            context_parts.append(f"## {skill.title}\n")
            context_parts.append(skill.content)
            context_parts.append("\n---\n")

        context_parts.append("\nè¯·åŸºäºä»¥ä¸ŠçŸ¥è¯†å›ç­”ç”¨æˆ·é—®é¢˜ã€‚å¦‚æœçŸ¥è¯†åº“ä¸­æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œè¯·è¯šå®è¯´æ˜ã€‚")

        return "\n".join(context_parts)


if __name__ == "__main__":
    # æµ‹è¯•
    from skill_loader import SkillLoader

    loader = SkillLoader("skills")
    chat_service = ChatService()

    # æµ‹è¯•1: ä½¿ç”¨çŸ¥è¯†åº“
    print("="*60)
    print("æµ‹è¯•1: ä½¿ç”¨çŸ¥è¯†åº“å›ç­”")
    skill = loader.get_skill("saskatchewan-pst")
    answer = chat_service.generate_answer(
        user_query="è¨çœçš„ PST ç¨ç‡æ˜¯å¤šå°‘ï¼Ÿ",
        loaded_skills=[skill] if skill else []
    )

    # æµ‹è¯•2: ä¸ä½¿ç”¨çŸ¥è¯†åº“
    print("\n" + "="*60)
    print("æµ‹è¯•2: ä¸ä½¿ç”¨çŸ¥è¯†åº“å›ç­”")
    answer = chat_service.generate_answer(
        user_query="ä»Šå¤©å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ",
        loaded_skills=[]
    )
