#!/usr/bin/env python3
"""
PDF æ–‡æœ¬æå–å™¨ MVP ç‰ˆæœ¬
åŸºäº Skill Seeker çš„ PyMuPDF æ–¹æ¡ˆï¼Œæ”¯æŒ OCR å’Œåˆ†é¡µå¤„ç†
ç”¨äºéªŒè¯ CRA T4012 ç­‰å¤§å‹ PDF çš„å¤„ç†èƒ½åŠ›
"""

import os
import time
import psutil
import traceback
import io
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass
from datetime import datetime

# PDF å¤„ç†åº“
import fitz  # PyMuPDF
from PIL import Image
import pytesseract

@dataclass
class PageResult:
    """å•é¡µå¤„ç†ç»“æœ"""
    page_number: int
    text: str
    text_quality: float  # æ–‡æœ¬è´¨é‡è¯„åˆ†
    has_images: bool
    needs_ocr: bool
    processing_time: float
    word_count: int
    char_count: int

@dataclass
class ExtractionResult:
    """å®Œæ•´æå–ç»“æœ"""
    file_path: str
    total_pages: int
    successful_pages: int
    pages_needing_ocr: int
    total_text: str
    processing_time: float
    memory_peak_mb: float
    pages: List[PageResult]
    metadata: Dict

class PDFTextExtractor:
    """PDF æ–‡æœ¬æå–å™¨ - MVP ç‰ˆæœ¬"""

    def __init__(self, enable_ocr: bool = True, ocr_language: str = "eng"):
        self.enable_ocr = enable_ocr
        self.ocr_language = ocr_language
        self.process = psutil.Process(os.getpid())

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            "pages_processed": 0,
            "ocr_used": 0,
            "errors": 0
        }

    def extract_pdf(self, pdf_path: str, max_pages: Optional[int] = None) -> ExtractionResult:
        """
        æå– PDF æ–‡æœ¬

        Args:
            pdf_path: PDF æ–‡ä»¶è·¯å¾„
            max_pages: æœ€å¤§å¤„ç†é¡µæ•°ï¼ˆNone è¡¨ç¤ºå…¨éƒ¨ï¼‰

        Returns:
            ExtractionResult: æå–ç»“æœ
        """
        print(f"\nğŸš€ å¼€å§‹å¤„ç† PDF: {pdf_path}")

        # è®°å½•å¼€å§‹æ—¶é—´å’Œå†…å­˜
        start_time = time.time()
        start_memory = self.process.memory_info().rss / 1024 / 1024  # MB

        try:
            # æ‰“å¼€ PDF
            doc = fitz.open(pdf_path)
            total_pages = len(doc)

            if max_pages:
                total_pages = min(total_pages, max_pages)
                print(f"ğŸ“„ é™åˆ¶å¤„ç†é¡µæ•°: {total_pages}")
            else:
                print(f"ğŸ“„ æ€»é¡µæ•°: {total_pages}")

            # æ£€æŸ¥ PDF æ˜¯å¦åŠ å¯†
            if doc.is_encrypted:
                print("âš ï¸ PDF æ–‡ä»¶å·²åŠ å¯†ï¼Œå°è¯•è§£å¯†...")
                if not doc.authenticate(""):
                    raise ValueError("æ— æ³•è§£å¯† PDF æ–‡ä»¶")

            # è·å– PDF å…ƒæ•°æ®
            metadata = self._extract_metadata(doc)

            # é€é¡µå¤„ç†
            pages = []
            successful_pages = 0
            pages_needing_ocr = 0

            for page_num in range(total_pages):
                try:
                    print(f"ğŸ“– å¤„ç†ç¬¬ {page_num + 1}/{total_pages} é¡µ...")
                    page_result = self._process_page(doc, page_num)

                    pages.append(page_result)

                    if page_result.text_quality > 0.1:  # æ–‡æœ¬è´¨é‡é˜ˆå€¼
                        successful_pages += 1

                    if page_result.needs_ocr:
                        pages_needing_ocr += 1

                    # æ›´æ–°ç»Ÿè®¡
                    self.stats["pages_processed"] += 1
                    if page_result.needs_ocr:
                        self.stats["ocr_used"] += 1

                    # å†…å­˜æ£€æŸ¥
                    current_memory = self.process.memory_info().rss / 1024 / 1024
                    if current_memory > 1024:  # è¶…è¿‡ 1GB
                        print(f"âš ï¸ å†…å­˜ä½¿ç”¨è¾ƒé«˜: {current_memory:.1f} MB")

                except Exception as e:
                    print(f"âŒ å¤„ç†ç¬¬ {page_num + 1} é¡µæ—¶å‡ºé”™: {e}")
                    self.stats["errors"] += 1
                    continue

            # åˆå¹¶æ‰€æœ‰æ–‡æœ¬
            total_text = self._combine_pages_text(pages)

            # è®¡ç®—å¤„ç†æ—¶é—´
            end_time = time.time()
            end_memory = self.process.memory_info().rss / 1024 / 1024

            processing_time = end_time - start_time
            memory_peak = max(start_memory, end_memory)

            # å…³é—­æ–‡æ¡£
            doc.close()

            # åˆ›å»ºç»“æœå¯¹è±¡
            result = ExtractionResult(
                file_path=pdf_path,
                total_pages=total_pages,
                successful_pages=successful_pages,
                pages_needing_ocr=pages_needing_ocr,
                total_text=total_text,
                processing_time=processing_time,
                memory_peak_mb=memory_peak,
                pages=pages,
                metadata=metadata
            )

            self._print_summary(result)
            return result

        except Exception as e:
            print(f"âŒ PDF å¤„ç†å¤±è´¥: {e}")
            print(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            raise

    def _process_page(self, doc, page_num: int) -> PageResult:
        """å¤„ç†å•ä¸ªé¡µé¢"""
        start_time = time.time()

        page = doc[page_num]

        # å°è¯•ç›´æ¥æ–‡æœ¬æå–
        text = page.get_text()
        text_quality = self._evaluate_text_quality(text)

        needs_ocr = False
        has_images = False

        # å¦‚æœæ–‡æœ¬è´¨é‡å¤ªä½ï¼Œå°è¯• OCR
        if text_quality < 0.3 and self.enable_ocr:
            print(f"  ğŸ”„ æ–‡æœ¬è´¨é‡è¾ƒä½ ({text_quality:.2f})ï¼Œå°è¯• OCR...")
            try:
                ocr_text = self._ocr_page(page)
                if ocr_text and len(ocr_text.strip()) > len(text.strip()):
                    text = ocr_text
                    needs_ocr = True
                    text_quality = self._evaluate_text_quality(text)
                    print(f"  âœ… OCR æˆåŠŸï¼Œæ–°æ–‡æœ¬è´¨é‡: {text_quality:.2f}")
                else:
                    print(f"  âš ï¸ OCR æœªæ”¹å–„æ–‡æœ¬è´¨é‡")
            except Exception as e:
                print(f"  âŒ OCR å¤±è´¥: {e}")

        # æ£€æŸ¥é¡µé¢æ˜¯å¦æœ‰å›¾åƒ
        image_list = page.get_images()
        has_images = len(image_list) > 0

        processing_time = time.time() - start_time

        return PageResult(
            page_number=page_num + 1,
            text=text.strip(),
            text_quality=text_quality,
            has_images=has_images,
            needs_ocr=needs_ocr,
            processing_time=processing_time,
            word_count=len(text.split()),
            char_count=len(text)
        )

    def _evaluate_text_quality(self, text: str) -> float:
        """è¯„ä¼°æ–‡æœ¬è´¨é‡"""
        if not text or len(text.strip()) < 10:
            return 0.0

        score = 0.0

        # 1. æ–‡æœ¬é•¿åº¦
        text_length = len(text.strip())
        if text_length > 100:
            score += 0.3
        elif text_length > 50:
            score += 0.2
        else:
            score += 0.1

        # 2. å•è¯å®Œæ•´æ€§
        words = text.split()
        if words:
            complete_words = sum(1 for word in words if word.isalpha() or '.' in word or ',' in word)
            word_completeness = complete_words / len(words)
            score += word_completeness * 0.3

        # 3. å¥å­ç»“æ„
        sentences = text.split('.')
        if len(sentences) > 1:
            score += 0.2

        # 4. å¸¸è§å­—ç¬¦æ£€æŸ¥
        common_chars = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789.,!?;:()-"
        char_ratio = sum(1 for c in text if c in common_chars) / len(text) if text else 0
        score += char_ratio * 0.2

        return min(score, 1.0)

    def _ocr_page(self, page) -> str:
        """å¯¹é¡µé¢è¿›è¡Œ OCR"""
        try:
            # å°†é¡µé¢è½¬æ¢ä¸ºå›¾åƒ
            pix = page.get_pixmap(matrix=fitz.Matrix(2.0, 2.0))  # 2x åˆ†è¾¨ç‡
            img_data = pix.tobytes("png")
            img = Image.open(io.BytesIO(img_data))

            # è¿›è¡Œ OCR
            text = pytesseract.image_to_string(img, lang=self.ocr_language)
            return text

        except Exception as e:
            print(f"    OCR é”™è¯¯: {e}")
            return ""

    def _extract_metadata(self, doc) -> Dict:
        """æå– PDF å…ƒæ•°æ®"""
        metadata = doc.metadata
        return {
            "title": metadata.get("title", ""),
            "author": metadata.get("author", ""),
            "subject": metadata.get("subject", ""),
            "creator": metadata.get("creator", ""),
            "producer": metadata.get("producer", ""),
            "creation_date": metadata.get("creationDate", ""),
            "modification_date": metadata.get("modDate", ""),
            "page_count": len(doc),
            "is_encrypted": doc.is_encrypted
        }

    def _combine_pages_text(self, pages: List[PageResult]) -> str:
        """åˆå¹¶æ‰€æœ‰é¡µé¢çš„æ–‡æœ¬"""
        combined_text = []

        for page in pages:
            if page.text:
                combined_text.append(f"\n=== ç¬¬ {page.page_number} é¡µ ===\n")
                combined_text.append(page.text)
                combined_text.append("\n")

        return "\n".join(combined_text)

    def _print_summary(self, result: ExtractionResult):
        """æ‰“å°å¤„ç†æ‘˜è¦"""
        print(f"\nğŸ“Š å¤„ç†å®Œæˆæ‘˜è¦:")
        print(f"  ğŸ“ æ–‡ä»¶: {Path(result.file_path).name}")
        print(f"  ğŸ“„ æ€»é¡µæ•°: {result.total_pages}")
        print(f"  âœ… æˆåŠŸå¤„ç†: {result.successful_pages}")
        print(f"  ğŸ” OCR ä½¿ç”¨: {result.pages_needing_ocr}")
        print(f"  â±ï¸  å¤„ç†æ—¶é—´: {result.processing_time:.2f} ç§’")
        print(f"  ğŸ§  å†…å­˜å³°å€¼: {result.memory_peak_mb:.1f} MB")
        print(f"  ğŸ“ æ€»å­—ç¬¦æ•°: {len(result.total_text):,}")
        print(f"  ğŸ“– æ€»è¯æ•°: {len(result.total_text.split()):,}")

        if result.processing_time > 0:
            pages_per_second = result.total_pages / result.processing_time
            print(f"  âš¡ å¤„ç†é€Ÿåº¦: {pages_per_second:.2f} é¡µ/ç§’")

        # è®¡ç®—å¹³å‡æ–‡æœ¬è´¨é‡
        if result.pages:
            avg_quality = sum(p.text_quality for p in result.pages) / len(result.pages)
            print(f"  ğŸ“ˆ å¹³å‡æ–‡æœ¬è´¨é‡: {avg_quality:.2f}")

def save_extraction_result(result: ExtractionResult, output_dir: str = "output"):
    """ä¿å­˜æå–ç»“æœ"""
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)

    # ç”Ÿæˆæ–‡ä»¶å
    base_name = Path(result.file_path).stem
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

    # ä¿å­˜å®Œæ•´æ–‡æœ¬
    text_file = output_path / f"{base_name}_extracted_{timestamp}.txt"
    with open(text_file, 'w', encoding='utf-8') as f:
        f.write(result.total_text)
    print(f"ğŸ’¾ æ–‡æœ¬å·²ä¿å­˜: {text_file}")

    # ä¿å­˜æ‘˜è¦ä¿¡æ¯
    summary_file = output_path / f"{base_name}_summary_{timestamp}.json"
    import json
    summary_data = {
        "file_path": result.file_path,
        "total_pages": result.total_pages,
        "successful_pages": result.successful_pages,
        "pages_needing_ocr": result.pages_needing_ocr,
        "processing_time": result.processing_time,
        "memory_peak_mb": result.memory_peak_mb,
        "total_chars": len(result.total_text),
        "total_words": len(result.total_text.split()),
        "metadata": result.metadata,
        "stats": {
            "pages_processed": len(result.pages),
            "ocr_used": sum(1 for p in result.pages if p.needs_ocr),
            "errors": 0
        }
    }

    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(summary_data, f, indent=2, ensure_ascii=False)
    print(f"ğŸ“Š æ‘˜è¦å·²ä¿å­˜: {summary_file}")

    return text_file, summary_file

# æµ‹è¯•å‡½æ•°
def test_pdf_extraction():
    """æµ‹è¯• PDF æå–åŠŸèƒ½"""
    print("ğŸ§ª PDF æ–‡æœ¬æå–å™¨æµ‹è¯•")
    print("=" * 50)

    # åˆ›å»ºæå–å™¨
    extractor = PDFTextExtractor(enable_ocr=True)

    # æŸ¥æ‰¾æµ‹è¯• PDF æ–‡ä»¶
    test_files = [
        # CRA T4012 æ–‡æ¡£
        "pdf/t4012-24e.pdf",
        "t4012-24e.pdf",
        "sample.pdf",
        "test.pdf"
    ]

    test_file = None
    for file_path in test_files:
        if Path(file_path).exists():
            test_file = file_path
            break

    if not test_file:
        print("âŒ æœªæ‰¾åˆ°æµ‹è¯• PDF æ–‡ä»¶")
        print("è¯·å°†æµ‹è¯• PDF æ–‡ä»¶æ”¾åœ¨ä»¥ä¸‹ä½ç½®ä¹‹ä¸€ï¼š")
        for file_path in test_files:
            print(f"  - {file_path}")
        return

    try:
        # é™åˆ¶å¤„ç†å‰10é¡µè¿›è¡Œæµ‹è¯•
        result = extractor.extract_pdf(test_file, max_pages=10)

        # ä¿å­˜ç»“æœ
        text_file, summary_file = save_extraction_result(result)

        # æ˜¾ç¤ºä¸€äº›æå–çš„æ–‡æœ¬æ ·æœ¬
        print(f"\nğŸ“ æ–‡æœ¬æ ·æœ¬ (å‰500å­—ç¬¦):")
        print("-" * 30)
        print(result.total_text[:500])
        print("-" * 30)

        return result

    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return None

if __name__ == "__main__":
    test_pdf_extraction()