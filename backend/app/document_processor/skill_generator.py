"""
Skill Generator - Convert processed documents to Skill files

Generates Markdown files with YAML front matter compatible with MVP skill_loader.py

Note: This module no longer depends on hardcoded TaxCategory enum.
Classification categories are now dynamically generated by LLM.
"""

import hashlib
import logging
import re
import time
from pathlib import Path
from typing import Dict, List, Optional

import yaml
from pydantic import BaseModel, Field

from .content_classifier import ClassificationResult

logger = logging.getLogger(__name__)


class SkillMetadata(BaseModel):
    """Skill metadata for YAML front matter."""

    id: str = Field(..., description="Unique skill identifier (kebab-case)")
    title: str = Field(..., description="Skill title")
    tags: List[str] = Field(default_factory=list, description="Tag list")
    description: str = Field(..., description="Short description (1-2 sentences)")
    domain: str = Field(default="tax", description="Domain")
    priority: str = Field(default="medium", description="Priority: low, medium, high")
    category: str = Field(..., description="Category (dynamically generated)")
    source: str = Field(default="", description="Source document")
    quality_grade: str = Field(default="", description="Quality grade")


class SkillContent(BaseModel):
    """Skill content structure."""

    metadata: SkillMetadata = Field(..., description="Skill metadata")
    markdown_body: str = Field(..., description="Markdown body content")


class SkillGenerator:
    """
    Skill file generator.

    Features:
    - Convert classified content to Skill format
    - Generate YAML front matter
    - Organize Markdown content
    - Generate file names and directory structure

    Note: No longer uses hardcoded category mappings.
    Tags and titles are generated dynamically based on LLM classification.
    """

    def __init__(self, output_dir: str = "skills"):
        """
        Initialize the skill generator.

        Args:
            output_dir: Output directory for Skill files
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.max_skill_lines = 500  # Claude Skills best practice

    def generate_skill(
        self,
        content: str,
        classification: ClassificationResult,
        source_file: str = "",
        title: Optional[str] = None
    ) -> SkillContent:
        """
        Generate a Skill.

        Args:
            content: Document content
            classification: Classification result (with dynamic category)
            source_file: Source file path
            title: Custom title (optional)

        Returns:
            SkillContent with metadata and markdown body
        """
        # 1. Generate Skill ID
        skill_id = self._generate_skill_id(
            classification.primary_category,
            source_file
        )

        # 2. Generate title
        if not title:
            title = self._generate_title(
                classification.primary_category,
                content
            )

        # 3. Generate description
        description = self._generate_description(content)

        # 4. Generate tags from classification
        tags = self._generate_tags(classification)

        # 5. Determine priority based on confidence
        priority = self._determine_priority(classification.confidence)

        # 6. Create metadata
        metadata = SkillMetadata(
            id=skill_id,
            title=title,
            tags=tags,
            description=description,
            domain="tax",
            priority=priority,
            category=classification.primary_category,
            source=source_file,
            quality_grade=classification.quality_metrics.quality_grade
        )

        # 7. Organize Markdown content
        markdown_body = self._organize_markdown_content(
            content,
            classification
        )

        return SkillContent(
            metadata=metadata,
            markdown_body=markdown_body
        )

    def save_skill(
        self,
        skill: SkillContent,
        subdirectory: Optional[str] = None
    ) -> Path:
        """
        Save Skill to file (legacy single-file mode).

        Args:
            skill: Skill content
            subdirectory: Optional subdirectory for organization

        Returns:
            Path to saved file
        """
        # Determine output directory
        if subdirectory:
            output_path = self.output_dir / subdirectory
        else:
            output_path = self.output_dir

        output_path.mkdir(parents=True, exist_ok=True)

        # Generate file path
        file_path = output_path / f"{skill.metadata.id}.md"

        # Generate full content
        full_content = self._render_skill_file(skill)

        # Write file
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(full_content)

        logger.info(f"Skill saved: {file_path}")
        return file_path

    def save_skill_directory(
        self,
        skill_id: str,
        raw_text: str,
        reference_chunks: List[dict],
        metadata: SkillMetadata,
        subdirectory: Optional[str] = None
    ) -> Path:
        """
        Save skill as directory structure (Skill_Seekers pattern).

        Creates:
        - skill_id/
          - SKILL.md (lightweight index)
          - references/
            - index.md (navigation)
            - {chunk-slug}.md (enhanced content)
          - raw/
            - full-extract.txt (original text)

        Args:
            skill_id: Skill identifier
            raw_text: Original extracted text
            reference_chunks: List of enhanced chunks with metadata
            metadata: Skill metadata
            subdirectory: Optional parent subdirectory

        Returns:
            Path to skill directory
        """
        # Create skill directory
        if subdirectory:
            skill_dir = self.output_dir / subdirectory / skill_id
        else:
            skill_dir = self.output_dir / skill_id

        skill_dir.mkdir(parents=True, exist_ok=True)

        # Create subdirectories
        (skill_dir / "references").mkdir(exist_ok=True)
        (skill_dir / "raw").mkdir(exist_ok=True)

        # 1. Save raw text
        self._save_raw_text(skill_dir / "raw" / "full-extract.txt", raw_text)

        # 2. Save reference chunks
        reference_files = []
        for chunk in reference_chunks:
            ref_path = self._save_reference_file(
                skill_dir / "references",
                chunk['slug'],
                chunk['title'],
                chunk['content'],
                chunk['chapter_num']
            )
            reference_files.append({
                'path': ref_path.name,
                'title': chunk['title'],
                'chapter_num': chunk['chapter_num']
            })

        # 3. Generate references/index.md
        self._create_reference_index(
            skill_dir / "references" / "index.md",
            reference_files,
            metadata
        )

        # 4. Generate SKILL.md
        self._create_skill_index(
            skill_dir / "SKILL.md",
            metadata,
            reference_files,
            len(raw_text)
        )

        logger.info(f"Skill directory created: {skill_dir}")
        return skill_dir

    def _save_raw_text(self, file_path: Path, content: str) -> None:
        """Save raw extracted text."""
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(content)
        logger.info(f"Raw text saved: {file_path}")

    def _save_reference_file(
        self,
        references_dir: Path,
        slug: str,
        title: str,
        content: str,
        chapter_num: int
    ) -> Path:
        """Save a single reference file."""
        file_path = references_dir / f"{slug}.md"

        # Format reference file content
        formatted_content = f"""# {title}

**Chapter {chapter_num}**

---

{content}
"""

        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(formatted_content)

        logger.info(f"Reference file saved: {file_path}")
        return file_path

    def _create_reference_index(
        self,
        index_path: Path,
        reference_files: List[dict],
        metadata: SkillMetadata
    ) -> None:
        """Create references/index.md navigation file."""
        content = f"""# {metadata.title} - Reference Index

**Source:** {metadata.source}
**Category:** {metadata.category}
**Quality:** {metadata.quality_grade}

---

## Available References

This documentation is organized into the following sections:

"""

        # Add table of contents
        for ref in sorted(reference_files, key=lambda x: x['chapter_num']):
            content += f"{ref['chapter_num']}. **[{ref['title']}]({ref['path']})** \n"

        content += f"""
---

**Total Chapters:** {len(reference_files)}

**Navigation:**
- Return to [SKILL.md](../SKILL.md)
- View [raw extracted text](../raw/full-extract.txt)
"""

        with open(index_path, 'w', encoding='utf-8') as f:
            f.write(content)

        logger.info(f"Reference index created: {index_path}")

    def _create_skill_index(
        self,
        skill_path: Path,
        metadata: SkillMetadata,
        reference_files: List[dict],
        raw_text_size: int
    ) -> None:
        """Create SKILL.md lightweight index file."""
        # Generate YAML front matter
        yaml_content = yaml.dump(
            metadata.model_dump(exclude_none=True),
            allow_unicode=True,
            sort_keys=False,
            default_flow_style=False
        )

        content = f"""---
{yaml_content}---

# {metadata.title}

{metadata.description}

---

## When to Use This Skill

Use this skill when you need information about:
{self._generate_use_cases(metadata)}

---

## Reference Documentation

This skill contains {len(reference_files)} reference chapters:

"""

        # Add compact table of contents
        for ref in sorted(reference_files, key=lambda x: x['chapter_num']):
            content += f"{ref['chapter_num']}. [{ref['title']}](references/{ref['path']})\n"

        content += f"""
**[View Full Index](references/index.md)** | **[Raw Text](raw/full-extract.txt)** ({raw_text_size:,} chars)

---

## Tags

{', '.join(f'`{tag}`' for tag in metadata.tags)}

---

## Quality Information

- **Grade:** {metadata.quality_grade}
- **Priority:** {metadata.priority}
- **Domain:** {metadata.domain}
- **Source:** {metadata.source}

---

*Generated by BeanFlow CRA Document Processor*
"""

        with open(skill_path, 'w', encoding='utf-8') as f:
            f.write(content)

        logger.info(f"SKILL.md index created: {skill_path}")

    def _deduplicate_content_chunks(self, reference_chunks):
        """Remove duplicate or similar content chunks."""
        seen_hashes = set()
        unique_chunks = []

        for chunk in reference_chunks:
            content_hash = hashlib.md5(chunk['content'].encode()).hexdigest()

            if content_hash not in seen_hashes:
                seen_hashes.add(content_hash)
                unique_chunks.append(chunk)
            else:
                logger.warning(f"Duplicate content detected: {chunk['title']}")

        return unique_chunks

    def _generate_continuous_chapters(self, reference_chunks):
        """Generate continuous chapter numbering."""
        # Sort by original chunk_id to maintain document order
        sorted_chunks = sorted(reference_chunks, key=lambda x: x['chapter_num'])
        continuous_chunks = []

        for i, chunk in enumerate(sorted_chunks, 1):
            # Reset chapter number to ensure continuity
            chunk['chapter_num'] = i
            continuous_chunks.append(chunk)

        return continuous_chunks

    def _improve_chapter_titles_with_toc(self, reference_chunks, toc_entries):
        """Improve chapter titles using TOC information."""

        # Sort TOC entries by character position
        sorted_toc = sorted([entry for entry in toc_entries if entry.char_start is not None],
                          key=lambda x: x.char_start)

        improved_chunks = []

        for chunk in reference_chunks:
            improved_title = chunk['title']

            # Find the best TOC entry for this chunk
            if sorted_toc:
                # Use simple heuristic: find TOC entry that might correspond to this chapter
                chapter_num = chunk['chapter_num']

                # Try to match by chapter number or position
                if chapter_num <= len(sorted_toc):
                    # Use chapter number as index (adjusted for 0-based)
                    toc_entry = sorted_toc[min(chapter_num - 1, len(sorted_toc) - 1)]
                    improved_title = f"{toc_entry.title}"

                # Fallback: look for matching "Section X" pattern
                if improved_title.startswith("Section"):
                    for toc_entry in sorted_toc:
                        if f"Section {chapter_num}" in improved_title or chapter_num == 1:
                            improved_title = toc_entry.title
                            break

            # If no improvement found, keep original
            chunk['title'] = improved_title
            improved_chunks.append(chunk)

        return improved_chunks

    def _generate_use_cases(self, metadata: SkillMetadata) -> str:
        """Generate use cases based on category and tags."""
        use_cases = []

        # Generate use cases from tags
        for tag in metadata.tags[:3]:
            use_cases.append(f"- {tag}-related information")

        # Add category-based use case
        if metadata.category:
            category_name = metadata.category.replace("-", " ").replace("_", " ").title()
            use_cases.append(f"- {category_name} guidance and procedures")

        return "\n".join(use_cases) if use_cases else "- Canadian tax information and guidance"

    def _generate_skill_id(
        self,
        category: str,
        source_file: str
    ) -> str:
        """
        Generate Skill ID.

        Format: {category}-{source-name} or {category}-{timestamp}

        Args:
            category: Category string (dynamically generated)
            source_file: Source file path

        Returns:
            Skill ID in kebab-case
        """
        # Generate prefix from category with defensive check for empty/None
        if not category or not category.strip():
            category_prefix = "general"
        else:
            category_prefix = category.replace("_", "-").replace(" ", "-").lower()
            # Clean special characters
            category_prefix = re.sub(r'[^a-z0-9-]', '-', category_prefix)
            category_prefix = re.sub(r'-+', '-', category_prefix).strip('-')
            # Fallback if category becomes empty after cleaning
            if not category_prefix:
                category_prefix = "general"

        # Extract name from source file
        if source_file:
            source_name = Path(source_file).stem
            # Clean filename
            source_name = re.sub(r'[^a-zA-Z0-9-]', '-', source_name.lower())
            source_name = re.sub(r'-+', '-', source_name).strip('-')
            skill_id = f"{category_prefix}-{source_name}"
        else:
            # Use timestamp
            timestamp = int(time.time())
            skill_id = f"{category_prefix}-{timestamp}"

        # Ensure ID doesn't exceed 50 characters
        if len(skill_id) > 50:
            skill_id = skill_id[:50].rstrip('-')

        return skill_id

    def _generate_title(
        self,
        category: str,
        content: str
    ) -> str:
        """Generate Skill title."""
        # Try to extract first heading from content
        title_match = re.search(r'^#\s+(.+)$', content, re.MULTILINE)
        if title_match:
            title = title_match.group(1).strip()
            # Limit length
            if len(title) <= 100:
                return title

        # Generate default title based on category with defensive check
        if not category or not category.strip():
            return "CRA Tax Guide"
        category_name = category.replace("-", " ").replace("_", " ").title()
        return f"{category_name} - CRA Guide"

    def _generate_description(self, content: str) -> str:
        """Generate short description from first paragraph, skipping page markers."""
        # Remove page markers first
        clean_content = re.sub(r'=== Page \d+ ===\n', '', content)

        # Remove markdown headings
        clean_content = re.sub(r'^#+\s+.+$', '', clean_content, flags=re.MULTILINE)
        clean_content = clean_content.strip()

        # Extract first meaningful paragraph
        paragraphs = clean_content.split('\n\n')
        first_paragraph = ""

        for para in paragraphs:
            if para.strip() and not para.strip().startswith('==='):
                first_paragraph = para.strip()
                break

        # Clean formatting
        first_paragraph = re.sub(r'\*\*(.+?)\*\*', r'\1', first_paragraph)
        first_paragraph = re.sub(r'\*(.+?)\*', r'\1', first_paragraph)
        first_paragraph = re.sub(r'\[(.+?)\]\(.+?\)', r'\1', first_paragraph)
        first_paragraph = first_paragraph.replace('\n', ' ')

        # Limit length
        if len(first_paragraph) > 200:
            first_paragraph = first_paragraph[:197] + "..."

        return first_paragraph or "CRA tax information"

    def _generate_tags(self, classification: ClassificationResult) -> List[str]:
        """Generate tag list from classification result."""
        tags = set()

        # Add semantic tags from LLM classification
        if classification.semantic_tags:
            for tag in classification.semantic_tags[:5]:
                tags.add(tag)

        # Add matched keywords as tags
        if classification.matched_keywords:
            for keyword in classification.matched_keywords[:3]:
                # Convert keyword to tag format
                tag = keyword.replace("_", " ").title()
                tags.add(tag)

        # Add category-based tag
        if classification.primary_category:
            category_tag = classification.primary_category.replace("-", " ").replace("_", " ").title()
            tags.add(category_tag)

        # Add secondary categories as tags
        for secondary in classification.secondary_categories[:2]:
            secondary_tag = secondary.replace("-", " ").replace("_", " ").title()
            tags.add(secondary_tag)

        # Add general tags
        tags.add("CRA")
        tags.add("Canadian Tax")

        # Convert to list and limit
        return sorted(list(tags))[:8]

    def _determine_priority(self, confidence: float) -> str:
        """Determine priority based on classification confidence."""
        if confidence >= 0.9:
            return "high"
        elif confidence >= 0.7:
            return "medium"
        else:
            return "low"

    def _organize_markdown_content(
        self,
        content: str,
        classification: ClassificationResult
    ) -> str:
        """Organize Markdown content."""
        sections = []

        # Ensure main heading exists
        if not content.strip().startswith('#'):
            title = self._generate_title(classification.primary_category, content)
            sections.append(f"# {title}\n")

        # Add main content
        sections.append(content.strip())

        # Add notice if quality is low
        if classification.quality_metrics.overall_score < 0.7:
            sections.append("\n## Notice\n")
            sections.append("This content was auto-generated. Please refer to official CRA documentation for the most accurate information.\n")

        # Add related topics if secondary categories exist
        if classification.secondary_categories:
            sections.append("\n## Related Topics\n")
            for cat in classification.secondary_categories[:3]:
                category_name = cat.replace("_", " ").replace("-", " ").title()
                sections.append(f"- {category_name}\n")

        return "\n".join(sections)

    def _render_skill_file(self, skill: SkillContent) -> str:
        """Render complete Skill file (YAML front matter + Markdown)."""
        # Convert metadata to dict
        metadata_dict = skill.metadata.model_dump(exclude_none=True)

        # Generate YAML front matter
        yaml_content = yaml.dump(
            metadata_dict,
            allow_unicode=True,
            sort_keys=False,
            default_flow_style=False
        )

        # Combine full content
        full_content = f"---\n{yaml_content}---\n\n{skill.markdown_body}\n"

        return full_content


def generate_and_save_skill(
    content: str,
    classification: ClassificationResult,
    output_dir: str = "skills",
    source_file: str = "",
    title: Optional[str] = None
) -> Path:
    """
    Convenience function to generate and save Skill.

    Args:
        content: Document content
        classification: Classification result
        output_dir: Output directory
        source_file: Source file path
        title: Custom title

    Returns:
        Path to saved Skill file
    """
    generator = SkillGenerator(output_dir)
    skill = generator.generate_skill(content, classification, source_file, title)

    # Save to subdirectory based on category
    subdirectory = classification.primary_category.replace(" ", "-").lower()
    return generator.save_skill(skill, subdirectory)
